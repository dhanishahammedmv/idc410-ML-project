{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment 3\n",
        "\n",
        "#Submitted by\n",
        "\n",
        "#Dhanish Ahammed MV\n",
        "#MS21218"
      ],
      "metadata": {
        "id": "sSCgqNjNZ7nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip provided file and extract required\n",
        "!unzip -o /content/1629377515-5e748a2d5fc288e9f69c5f86\\ \\(1\\).zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbrzViXV89fB",
        "outputId": "bfab49d8-d91c-4c71-94b5-3e744b1ca24f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/1629377515-5e748a2d5fc288e9f69c5f86 (1).zip\n",
            "  inflating: mnist_train.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "UozcIAwc7yVL"
      },
      "outputs": [],
      "source": [
        "#import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1\n",
        "\n",
        "Here you must read an input file. Each line contains 785 numbers (comma delimited): the first number in each row denotes the class label: 0 corresponds to digit 0, 1 corresponds to digit 1, etc. The rest of the values are the 784 pixel values between 0 and 255 correspondig to black and white images.  As a warm up  question, load the data.\n",
        "\n",
        "For this problem you must write a function that takes a file path as an argument which contains  this data. Your function must return two values (x and y) that contains the data from the file as  described. Specifically, the first return value (x) must be a matrix where the rows are individual  examples of images, and the columns are individual pixels (n x 784 matrix). The second return value  must be a list/array of real numbers representing the labels of the examples (rows) in x.\n",
        "\n",
        "eg:\n",
        "\n",
        "1.0,0.0,1.0,0.0,....0.0,0.25,0.0,0.0\n",
        "\n",
        "...\n",
        "\n",
        "1.0,0.0,1.0,0.0,...,1.0,0.0,0.0,0.96776\n",
        "\n",
        "x = [\n",
        "\n",
        "[1.0,0.0,1.0,0.0,....0.0,0.25,0.0,0.0]\n",
        "\n",
        "...\n",
        "\n",
        "[1.0,0.0,1.0,0.0,...,1.0,0.0,0.0,0.96776]\n",
        "\n",
        "]\n",
        "\n",
        "y = [5,...,2]"
      ],
      "metadata": {
        "id": "pg_pfU11X9Ix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANSWER 1"
      ],
      "metadata": {
        "id": "xiitYO8oXrd5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JoFsZRJe7yVO"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"mnist_train.csv\")\n",
        "X = np.array(df.iloc[:,1:785])/255\n",
        "Y = np.array(df[\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2\n",
        "\n",
        "Implement the backpropagation algorithm in a zero hidden layer neural network (weights between input and output nodes). The output layer should be a softmax output over 10 classes corresponding to 10 classes of handwritten digits (e.g. An architecture: 784 > 10). Your backprop code should minimize the cross-entropy function for multi-class classification problems (categorical  cross entropy).\n",
        "\n",
        "\n",
        "\n",
        "where j is the class label\n",
        "\n",
        "This step should be done with a full step of gradient descent, not stochastic gradient descent or rmsprop. For this  problem you must write a function that takes as an input a matrix of x values, a list of y values (as  returned from problem 1), a weight matrix, and a learning rate and performs a single step of  backpropagation. You will need to do both a forward step with the inputs, and then a backward prop to  get the gradients. Return the updated weight matrix and bias in the same format as it was passed.\n",
        "\n",
        "The list of weight matrices will be a list with 1 entry where the only entry is a matrix in the  format where the rows represent all of the outgoing weights for a neuron in the input layer and the  columns represent the weights for the incoming neurons. A specific row column index will give you the  weight for a neuron to neuron connection.\n",
        "\n",
        "The list of bias vectors will be in the form where each entry in the list is a vector with the same  length as the first set of weights. (e.g. For an architecture of 784 > 10, there will be a single element list  with a vector of size 10)."
      ],
      "metadata": {
        "id": "KHE068S2YIr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANSWER 2"
      ],
      "metadata": {
        "id": "HUMqtpnGXZRW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cchE3Vfd7yVQ",
        "outputId": "bb92f78b-bd41-4042-a85f-3e5b995dbfe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 0.2386\n",
            "Epoch 20: loss = 0.1206\n",
            "Epoch 40: loss = 0.0884\n",
            "Epoch 60: loss = 0.0744\n",
            "Epoch 80: loss = 0.0664\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.00256273, -0.06600526,  0.05410788, ..., -0.01516264,\n",
              "         -0.03800385, -0.11119254],\n",
              "        [ 0.00862694,  0.02516188, -0.02817639, ..., -0.02042698,\n",
              "         -0.0258828 ,  0.07300685],\n",
              "        [-0.06792594, -0.03998857,  0.0095788 , ..., -0.01201272,\n",
              "         -0.02471961, -0.06152379],\n",
              "        ...,\n",
              "        [ 0.04452826,  0.01817994, -0.02118921, ..., -0.01404845,\n",
              "         -0.01218868,  0.02777768],\n",
              "        [ 0.04087397,  0.04071925, -0.01566047, ..., -0.01363192,\n",
              "         -0.01624442,  0.02410428],\n",
              "        [-0.06461566, -0.03825433,  0.02731732, ..., -0.04538838,\n",
              "          0.04788461, -0.00829578]]),\n",
              " array([-0.05588458,  0.09295315, -0.02197461, -0.02456514,  0.02934742,\n",
              "         0.05137224, -0.00675528,  0.04828548, -0.10449741, -0.00828126]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "np.random.seed(100000) # Setting the seed for reproducibility\n",
        "\n",
        "# One hot encoding the labels into 10 classes\n",
        "Y_class = np.array([(i)*[0]+[1]+(9-i)*[0] for i in Y])\n",
        "\n",
        "# Define the softmax function\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x)\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "# Define the forward pass function\n",
        "def forward(x,w,b):\n",
        "    z = np.dot(x, w) + b\n",
        "    return softmax(z)\n",
        "\n",
        "# Defining the training loop\n",
        "def zero_layer_mlp(x,y,w,b,lr):\n",
        "    num_iter = 100\n",
        "    loss_list = []\n",
        "    for iter in range(num_iter):\n",
        "        # Forward pass\n",
        "        y_pred = forward(x,w,b)\n",
        "\n",
        "        # Calculating the cross entropy loss\n",
        "        loss = -np.mean(y * np.log(y_pred))\n",
        "        loss_list.append(loss)\n",
        "\n",
        "        # Calculating the gradients\n",
        "        grad_w = np.dot(x.T, y_pred - y) /X.shape[0]\n",
        "        grad_b = np.mean(y_pred - y, axis=0)\n",
        "\n",
        "        # Updating the weights and biases\n",
        "        w = w-lr* grad_w\n",
        "        b = b-lr* grad_b\n",
        "\n",
        "        # Print the loss every 10 epochs\n",
        "        if iter % 20 == 0:\n",
        "            print(f\"Epoch {iter}: loss = {loss:.4f}\")\n",
        "\n",
        "    return(w,b)\n",
        "\n",
        "# Initializing the weights and biases\n",
        "n = X.shape[1]\n",
        "m = Y_class.shape[1]\n",
        "w = np.random.randn(n,m) / np.sqrt(n)\n",
        "b = np.zeros(m)\n",
        "\n",
        "zero_layer_mlp(X,Y_class,w,b,0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3\n",
        "\n",
        "Extend your code from problem 2 to support a single layer neural network with n hidden units (e.g. An  architecture: 784 > 10 > 10). These hidden units should be using sigmoid activations.\n",
        "\n",
        "For this problem you must write a function that takes as an input a matrix of x values, a list of y  values (as returned from problem 1), list of weight matrices, a list of bias vectors, and a learning rate and performs a single step of backpropagation. You will need to do both a forward step with the inputs to get the outputs, and then a backward prop to get the gradients. Return the  updated weight matrix and bias in the same format as it was passed.\n",
        "\n",
        "The list of weight matrices is a list with 2 entries where each entry in the list contains a single weight matrix as previously defined in problem 2. For a network with shape 784 > 10 > 10 the passed list  of weight matrices would look like this: [matrix with shape 784x10, matrix with shape 10x10]. Note:  though a hidden layer of size 10 is used as an example here, your code must be able to support a hidden  layer of dimension n.\n",
        "\n",
        "The list of bias vectors will be in the form where each entry in the list is a vector with the same  length as the first set of weights. (e.g. For an architecture of 784 > 10 > 10, there will be a two element  list with an vector of size 10 and a vector of size 10)"
      ],
      "metadata": {
        "id": "VF1HvuHUYXev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANSWER 3"
      ],
      "metadata": {
        "id": "1lwQUByUXWf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "XejJ8nPM7yVU",
        "outputId": "9b45a528-7d30-450d-c0dd-70e478a72d07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 0.2393\n",
            "Epoch 20: loss = 0.2220\n",
            "Epoch 40: loss = 0.2133\n",
            "Epoch 60: loss = 0.2054\n",
            "Epoch 80: loss = 0.1978\n",
            "[array([[ 0.00256273, -0.06600526,  0.05410788, ..., -0.01516264,\n",
            "        -0.03800385, -0.11119254],\n",
            "       [ 0.00862694,  0.02516188, -0.02817639, ..., -0.02042698,\n",
            "        -0.0258828 ,  0.07300685],\n",
            "       [-0.06792594, -0.03998857,  0.0095788 , ..., -0.01201272,\n",
            "        -0.02471961, -0.06152379],\n",
            "       ...,\n",
            "       [ 0.04452826,  0.01817994, -0.02118921, ..., -0.01404845,\n",
            "        -0.01218868,  0.02777768],\n",
            "       [ 0.04087397,  0.04071925, -0.01566047, ..., -0.01363192,\n",
            "        -0.01624442,  0.02410428],\n",
            "       [-0.06461566, -0.03825433,  0.02731732, ..., -0.04538838,\n",
            "         0.04788461, -0.00829578]]), array([[-0.20915034,  0.07774491,  0.45083931, -0.04617377, -0.41758153,\n",
            "         0.63688707, -0.25639866, -0.12657251,  0.91276676, -0.30491518],\n",
            "       [-0.12526245,  0.78158284,  0.05785329, -0.29687989, -0.07655511,\n",
            "         0.35547708,  0.4779392 , -0.13224126, -0.41681173,  0.02228871],\n",
            "       [ 0.09054543, -0.46136249, -0.49385108, -0.84713665,  0.01677176,\n",
            "        -0.76680129, -0.16949116,  0.36649356,  0.24071132,  0.53186106],\n",
            "       [ 0.44894555, -0.11037542, -0.1165896 ,  0.30516526,  0.65996907,\n",
            "         0.11483422,  0.06468479, -0.21763602, -0.09805334, -0.3035877 ],\n",
            "       [ 0.26313372, -0.03298898, -0.33270651,  0.65489714, -0.65008218,\n",
            "        -0.20799607,  0.2588489 , -0.10376404, -0.30400645,  0.10386139],\n",
            "       [-0.07357076,  0.65837363,  0.05376642,  0.26968764,  0.02343518,\n",
            "         0.32249935, -0.07527903,  0.76010643,  0.01782756, -0.22851617],\n",
            "       [-0.38315551,  0.26650665,  0.04441676, -0.43510046, -0.11767623,\n",
            "         0.44209227,  0.32628851, -0.28359832,  0.07039605,  0.40952731],\n",
            "       [ 0.26174778, -0.6566822 ,  0.65431932,  0.261095  ,  0.16897066,\n",
            "        -0.04896495, -0.10256575,  0.81634922, -0.19303229, -0.04028817],\n",
            "       [ 0.05512781, -0.01573381, -0.12916791,  0.36063713, -0.0802372 ,\n",
            "         0.47218218, -0.3219222 , -0.20474786,  0.00940812, -0.28660764],\n",
            "       [-0.08390806,  0.19975745, -0.18678842,  0.00962634, -0.04160168,\n",
            "        -0.61217725,  0.19254904,  0.01916703, -0.34869949,  0.07926169]])]\n",
            "[array([-0.0358693 ,  0.02336743, -0.01345927,  0.00205019, -0.01797764,\n",
            "        0.01766444,  0.01361432, -0.02146506, -0.00891463,  0.02107461]), array([-0.05632477,  0.10061175,  0.08501706,  0.01771703,  0.19336534,\n",
            "       -0.18363283, -0.01483925, -0.21650112,  0.0244404 ,  0.05014638])]\n",
            "(784, 10) (10, 10)\n",
            "(10,) (10,)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(100000)\n",
        "\n",
        "# One hot encoding the labels into 10 classes\n",
        "Y_class = np.array([(i)*[0]+[1]+(9-i)*[0] for i in Y])\n",
        "\n",
        "# Defining the sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Defining the softmax function\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x)\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "# Defining the forward pass function\n",
        "def forward(x,w1,w2,b1,b2):\n",
        "    h = sigmoid(np.dot(x, w1) + b1)\n",
        "    z = np.dot(h, w2) + b2\n",
        "    return softmax(z)\n",
        "\n",
        "# Defining the cost function\n",
        "def cost(y_true, y_pred):\n",
        "    return -np.mean(y_true * np.log(y_pred))\n",
        "\n",
        "# Defining the training loop\n",
        "def single_layer_mlp(x,y,W,B,lr):\n",
        "    n_epochs = 100\n",
        "    [w1,w2]=W\n",
        "    [b1,b2]=B\n",
        "    for epoch in range(n_epochs):\n",
        "        # Forward pass\n",
        "        h = sigmoid(np.dot(x, w1) + b1)\n",
        "        y_pred = forward(x,w1,w2,b1,b2)\n",
        "\n",
        "        # Calculating the cross entropy cost\n",
        "        loss = cost(y, y_pred)\n",
        "\n",
        "        # Calculating the gradients\n",
        "        grad_z = y_pred - y\n",
        "        grad_w2 = np.dot(h.T, grad_z) / x.shape[0]\n",
        "        grad_b2 = np.mean(grad_z, axis=0)\n",
        "        grad_h = np.dot(grad_z, w2.T) * h * (1 - h)\n",
        "        grad_w1 = np.dot(x.T, grad_h) / x.shape[0]\n",
        "        grad_b1 = np.mean(grad_h, axis=0)\n",
        "\n",
        "        # Updating the weights and biases\n",
        "        w2 = w2-lr * grad_w2\n",
        "        b2 = b2-lr * grad_b2\n",
        "        w1 = w1-lr * grad_w1\n",
        "        b1 = b1-lr * grad_b1\n",
        "\n",
        "        # Print the loss every 10 epochs\n",
        "        if epoch % 20 == 0:\n",
        "            print(f\"Epoch {epoch}: loss = {loss:.4f}\")\n",
        "\n",
        "    W = [w1,w2]\n",
        "    B = [b1,b2]\n",
        "    return(W,B)\n",
        "\n",
        "# Initializing the weights and biases\n",
        "n = X.shape[1] # number of features\n",
        "m = Y_class.shape[1] # number of classes\n",
        "n_hu = 10  # number of hidden units\n",
        "\n",
        "w1 = np.random.randn(n,n_hu) / np.sqrt(n)\n",
        "b1 = np.zeros(n_hu)\n",
        "w2 = np.random.randn(n_hu, m) / np.sqrt(n_hu)\n",
        "b2 = np.zeros(m)\n",
        "\n",
        "Weight = [w1,w2]\n",
        "Bias = [b1,b2]\n",
        "\n",
        "W,B=single_layer_mlp(X,Y_class,Weight,Bias,0.1)\n",
        "print(W)\n",
        "print(B)\n",
        "print(W[0].shape,W[1].shape)\n",
        "print(B[0].shape,B[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4\n",
        "\n",
        "Extend your code from problem 3 (use cross entropy error) and implement a multi-layer neural  network, starting with a simple architecture containing any number of hidden units in each layer (e.g. With  architecture: 784 > 10 > 10 > 10). These hidden units should be using sigmoid activations.\n",
        "\n",
        "For this problem you must write a function that takes as an input a matrix of x values, a list of y  values (as returned from problem 1), list of weight matrices, a list of bias vectors, and a learning rate and  performs a single step of backpropagation. You will need to do both a forward step with the inputs to  get the outputs, and then a backward prop to get the gradients. Return the updated weight matrix and  bias in the same format as it was passed.\n",
        "\n",
        "The list of weight matrices is a list with k entries where each entry in the list contains a single  weight matrix as previously defined in problem 2. For a network with shape 784 > 10 > 10 > 10 the  passed list of weight matrices would look like this: [matrix with shape 784x10, matrix with shape 10x10,  matrix with shape 10x10]. Note: though a hidden layer of size 10 is used as an example here, your code  must be able to support a hidden layer of dimension n.\n",
        "\n",
        "The list of bias vectors will be in the form where each entry in the list is a vector with the same  length as the first set of weights. (e.g. For an architecture of 784 > 10 > 10, there will be a two element  list with an vector of size 10 and a vector of size 10)"
      ],
      "metadata": {
        "id": "QnVjPnskYg-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANSWER 4"
      ],
      "metadata": {
        "id": "T-KTZfaUXTfI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VhJVjj5X7yVV",
        "outputId": "8d880a8c-0faf-49e9-a11b-84f08989628f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 2.438898925185021\n",
            "Epoch 10: loss = 2.330165493663167\n",
            "Epoch 20: loss = 2.307874446294917\n",
            "Epoch 30: loss = 2.302199309110229\n",
            "Epoch 40: loss = 2.3006168010502637\n",
            "Epoch 50: loss = 2.3000525886326537\n",
            "Epoch 60: loss = 2.2997393986846277\n",
            "Epoch 70: loss = 2.2994873152276347\n",
            "Epoch 80: loss = 2.299249216088691\n",
            "Epoch 90: loss = 2.2990131994206084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[ 0.00256273, -0.06600515,  0.05410779, ..., -0.02042694,\n",
              "          -0.02588275,  0.07300673],\n",
              "         [-0.06792583, -0.03998851,  0.00957879, ...,  0.01156511,\n",
              "           0.02280227,  0.04486038],\n",
              "         [ 0.04719391, -0.01432991,  0.04285393, ...,  0.00844747,\n",
              "           0.00151294,  0.04007569],\n",
              "         ...,\n",
              "         [ 0.00047193,  0.05446774, -0.07609704, ..., -0.04234888,\n",
              "          -0.03934672, -0.01621983],\n",
              "         [ 0.03255095,  0.05758201,  0.10453215, ..., -0.01574548,\n",
              "          -0.02864816,  0.07133386],\n",
              "         [-0.06647086, -0.03183223,  0.01672802, ...,  0.02687025,\n",
              "           0.01034864,  0.01300802]]),\n",
              "  array([[ 2.08615438e-01, -1.71879157e-01,  3.99487741e-01,\n",
              "           6.37495386e-02, -1.45592186e-01, -2.97372146e-03,\n",
              "          -9.38569293e-02, -4.10408013e-01, -3.62697567e-01,\n",
              "          -4.28099655e-01,  8.37920355e-02, -3.05314556e-01,\n",
              "          -1.39726704e-01,  2.08299421e-01,  1.62317473e-01,\n",
              "          -1.55511186e-02, -1.61954589e-02, -2.35213301e-01,\n",
              "           1.02052055e-01,  3.20083354e-01],\n",
              "         [ 2.11335743e-01,  2.25118402e-01,  2.55714601e-01,\n",
              "           2.29595669e-01,  5.23846469e-02,  2.02501144e-01,\n",
              "           2.70679244e-02,  6.74883134e-02,  5.55451598e-02,\n",
              "           2.04809437e-01, -3.18676834e-01, -3.36695746e-01,\n",
              "          -2.79699158e-02,  4.98457946e-02, -1.28109834e-01,\n",
              "          -7.45617960e-02,  6.85094120e-02, -4.35007487e-02,\n",
              "          -7.65238376e-02, -1.34757124e-01],\n",
              "         [-3.10290427e-01, -1.19783400e-01, -4.59808437e-02,\n",
              "          -1.86092917e-01,  4.85719670e-02,  2.62523933e-01,\n",
              "           1.65741384e-01,  4.26039099e-01,  1.19180505e-01,\n",
              "           3.87068788e-01,  1.44901454e-02, -2.47965401e-01,\n",
              "           7.93678572e-01, -7.88428042e-02, -4.25650332e-01,\n",
              "          -1.33033864e-01,  1.81110079e-01,  5.90249213e-02,\n",
              "           2.78109873e-02, -8.57365623e-02],\n",
              "         [ 2.33532863e-01,  3.28924650e-01,  8.62087638e-02,\n",
              "          -6.24940689e-02, -2.16945476e-01, -2.35442685e-02,\n",
              "           2.06261555e-03,  1.03101122e-01, -3.17892582e-01,\n",
              "           2.57137114e-03,  1.14933833e-01,  2.46169303e-01,\n",
              "           4.38595470e-01,  2.06942526e-02, -8.80624890e-02,\n",
              "           8.28697024e-02,  2.88317650e-01,  2.88019019e-01,\n",
              "           2.29098981e-01, -1.56372755e-01],\n",
              "         [ 1.88574146e-01, -3.02429022e-01, -2.14660929e-02,\n",
              "           1.69534276e-01, -1.13605559e-01,  1.17951531e-01,\n",
              "          -1.36737964e-01, -2.40098077e-01,  2.95253018e-01,\n",
              "           9.86090076e-02,  2.74859624e-01,  4.30423870e-01,\n",
              "           7.84174353e-02, -2.06076960e-01, -2.84758212e-01,\n",
              "          -1.46852007e-01,  1.65814420e-01, -1.33807374e-01,\n",
              "           4.87951860e-01,  5.33401766e-02],\n",
              "         [ 4.45209029e-02,  2.47265637e-01, -8.19591755e-02,\n",
              "           2.11019723e-01, -2.96310684e-01, -4.42485257e-01,\n",
              "           3.23775975e-01,  1.30008772e-01,  2.36633986e-01,\n",
              "           2.23667456e-01, -1.65292553e-01, -3.39329804e-01,\n",
              "           5.06384233e-02,  2.20744936e-01, -1.73229839e-01,\n",
              "          -1.55571329e-01, -1.75024543e-02, -5.17148226e-01,\n",
              "          -5.12164990e-02,  5.73050004e-02],\n",
              "         [-2.18117889e-01, -1.99635854e-01,  3.82167476e-02,\n",
              "           6.33405808e-01,  2.86777151e-01,  1.04877983e-01,\n",
              "          -2.81384857e-01,  1.01588433e-01,  2.29871297e-01,\n",
              "          -1.80256688e-01, -1.33721209e-01,  3.34264150e-01,\n",
              "           2.06581987e-01, -4.01977410e-01, -2.19879691e-01,\n",
              "           1.17733315e-01,  3.86745151e-01, -2.61483212e-01,\n",
              "           9.38598852e-03,  2.29237406e-01],\n",
              "         [ 4.99387188e-01,  3.13534432e-01, -1.76112123e-01,\n",
              "          -1.57994227e-01, -1.44741343e-01, -2.84123352e-01,\n",
              "           1.88062100e-01,  2.30275847e-02,  4.89210954e-01,\n",
              "          -1.84914233e-01, -2.13092869e-01,  4.66120847e-01,\n",
              "           3.70488567e-02,  7.75496783e-02,  3.05112148e-01,\n",
              "           1.89701053e-01,  1.38693050e-01,  1.74705851e-01,\n",
              "          -3.85318912e-01,  3.59252863e-02],\n",
              "         [-6.79398644e-02,  1.32189915e-02, -8.69662388e-02,\n",
              "           8.05401565e-02,  4.60502232e-01, -1.54868535e-01,\n",
              "          -3.66111046e-01,  4.29606025e-03,  1.05224630e-01,\n",
              "           1.39150839e-01,  3.41077928e-01, -3.53747979e-01,\n",
              "          -4.26647642e-02,  1.14699575e-01, -2.31003370e-01,\n",
              "           2.08970477e-01,  3.24075884e-01,  1.35000218e-01,\n",
              "           1.32466761e-01,  1.26452123e-01],\n",
              "         [ 3.99962749e-01, -2.22793472e-01,  1.65644873e-01,\n",
              "          -1.13593674e-01,  1.94618399e-01,  8.01635817e-02,\n",
              "           1.98446490e-01,  1.01304859e-01,  1.25155227e-01,\n",
              "          -2.34748720e-02, -1.05213052e-01,  1.34498950e-01,\n",
              "          -1.10287947e-01, -9.64853090e-02, -2.52258842e-02,\n",
              "           1.98399012e-01,  3.45609400e-02,  1.41365941e-02,\n",
              "           4.78455624e-01, -3.03744008e-01],\n",
              "         [ 1.01801500e-01,  7.00638513e-02,  2.34265613e-01,\n",
              "          -4.74781887e-02,  2.19495722e-01, -3.56259856e-01,\n",
              "          -2.70043094e-01, -4.75248917e-02,  4.49685412e-02,\n",
              "           2.73899953e-01, -2.02429654e-02, -4.67768905e-01,\n",
              "           1.07518200e-01, -2.76353348e-01, -2.10840116e-01,\n",
              "          -1.35265111e-02,  1.10951745e-01,  1.50704974e-01,\n",
              "           3.66951578e-01, -9.25129807e-02],\n",
              "         [-5.83127425e-01, -1.63867681e-01, -2.67894820e-01,\n",
              "           1.37789521e-01,  2.25473378e-01,  1.27334613e-01,\n",
              "          -2.05762465e-02, -8.35899969e-02,  1.01404387e-01,\n",
              "           1.19736294e-01, -2.92887106e-01, -1.66378065e-02,\n",
              "          -2.09987014e-02, -2.49810986e-01,  1.59531625e-01,\n",
              "          -3.46635391e-01, -1.44284885e-01,  1.95789255e-01,\n",
              "           1.10944483e-01, -1.90159469e-01],\n",
              "         [ 1.01648813e-01, -7.61274711e-02, -3.64448941e-02,\n",
              "           3.00858952e-01, -1.26446514e-01, -2.42470285e-01,\n",
              "          -2.27293857e-02,  1.30184912e-01, -1.44380430e-01,\n",
              "           1.74950051e-01,  1.06880126e-01, -6.01001450e-02,\n",
              "          -6.73917961e-02,  4.84358442e-02, -1.72164830e-01,\n",
              "           4.93221216e-03, -1.16861819e-01, -2.91451009e-02,\n",
              "          -3.72846727e-01,  2.56877561e-01],\n",
              "         [-1.34430725e-01, -2.38894024e-01, -1.41424002e-01,\n",
              "           4.97899247e-02, -1.41690283e-01, -4.47810253e-01,\n",
              "           1.16784030e-02,  1.81143084e-01, -2.43996840e-01,\n",
              "           2.37903347e-01, -3.67273052e-01,  1.60224186e-01,\n",
              "          -1.37587616e-01, -3.08684563e-01, -2.68389284e-01,\n",
              "          -5.09959185e-01, -4.91231480e-02,  2.19681545e-01,\n",
              "           9.10502076e-02, -1.14517444e-01],\n",
              "         [ 9.09936474e-02,  1.60669886e-01,  4.14235445e-02,\n",
              "           3.57642053e-01, -7.86521686e-02,  5.28069631e-02,\n",
              "           4.53566842e-01, -6.19812880e-03,  2.68915672e-01,\n",
              "           3.73493379e-01, -5.17267756e-02, -1.45536530e-01,\n",
              "          -1.99172187e-01,  1.32908512e-02,  3.20169019e-01,\n",
              "          -1.50123310e-01, -3.36797007e-01,  1.32258119e-01,\n",
              "           1.46284319e-01, -1.97339479e-01],\n",
              "         [ 7.05648344e-01,  2.01224728e-02,  2.19999299e-01,\n",
              "           3.67255839e-01, -2.56805432e-02, -2.58246321e-01,\n",
              "           1.04000038e-01,  1.90477193e-01,  2.40896995e-01,\n",
              "          -1.27130266e-01,  1.02192707e-01,  1.31199341e-01,\n",
              "           1.15191623e-01,  7.20811877e-01, -1.12927462e-01,\n",
              "           2.00439074e-02,  3.23173620e-02,  7.34535367e-02,\n",
              "          -1.79678327e-01,  2.65853863e-01],\n",
              "         [ 1.39755905e-01, -3.89513798e-03, -3.73722769e-01,\n",
              "           4.35110645e-02,  2.73152713e-01, -1.99895979e-01,\n",
              "          -3.66073793e-01,  5.06059167e-02,  2.88405184e-01,\n",
              "          -6.33615796e-02, -1.33202563e-01,  2.07221751e-02,\n",
              "           3.90192064e-02,  6.81450807e-02,  3.36030603e-01,\n",
              "          -3.34536565e-01, -9.37842416e-02, -3.40105963e-01,\n",
              "           3.86078428e-02, -1.94897084e-01],\n",
              "         [-5.82485310e-02, -6.96249944e-02,  3.61879761e-03,\n",
              "          -6.32813120e-02, -1.80772209e-04,  1.11072616e-01,\n",
              "          -2.08353574e-01,  1.32720879e-01, -8.93296704e-03,\n",
              "           2.43835440e-01, -5.80608530e-02,  2.92131173e-01,\n",
              "          -1.57772325e-02, -1.56588754e-01, -2.17471562e-01,\n",
              "          -3.77494891e-01,  1.44337219e-01,  2.61147148e-01,\n",
              "           1.80343754e-01,  4.16463563e-02],\n",
              "         [-1.59191852e-01,  1.45547807e-01,  6.01555165e-02,\n",
              "          -1.24511712e-01,  3.26180013e-01, -1.64822694e-01,\n",
              "           3.28364440e-01,  2.00928727e-01,  1.50912037e-01,\n",
              "           1.90855046e-01, -3.36595628e-01, -2.12697604e-01,\n",
              "          -1.34758585e-01, -2.01278791e-01,  2.31766321e-01,\n",
              "          -1.91764808e-01,  7.90155543e-02,  1.74300033e-01,\n",
              "           1.77464445e-01, -4.77611382e-01],\n",
              "         [ 5.28477315e-01,  7.33329337e-02, -1.80256646e-01,\n",
              "          -2.22840998e-01,  1.58960417e-02,  2.20332898e-01,\n",
              "           2.20559093e-01, -1.34216487e-01,  3.55655152e-01,\n",
              "           1.62345626e-01, -3.17226799e-02,  7.91719683e-02,\n",
              "           1.03821099e-01,  6.52644511e-02,  1.24178766e-01,\n",
              "          -5.26986696e-01,  4.86976461e-02, -9.16499404e-02,\n",
              "           6.82202567e-02, -2.19026092e-02]]),\n",
              "  array([[-9.84081196e-02,  1.36567793e-01,  1.42972917e-01,\n",
              "           7.50479420e-02,  8.10074392e-02, -3.10378136e-01,\n",
              "          -3.67691403e-01,  3.28931509e-01,  1.77476983e-01,\n",
              "           1.36342471e-02, -1.98243130e-01, -1.52021643e-01,\n",
              "           4.39545484e-02,  4.95344886e-02,  2.82644687e-02,\n",
              "           4.83274988e-01,  2.54263630e-01, -3.03833829e-01,\n",
              "           2.37793868e-01,  3.51041882e-01],\n",
              "         [-3.46884441e-01,  1.63604947e-02,  8.20485834e-02,\n",
              "          -5.69035234e-01,  4.07943274e-01,  1.83769016e-01,\n",
              "          -2.67544948e-01, -4.54255216e-01, -1.86745394e-01,\n",
              "           1.59483485e-01, -3.28208867e-01, -2.52925723e-01,\n",
              "          -2.93505687e-01, -2.09471256e-01,  2.81540894e-01,\n",
              "          -4.35585315e-01,  1.89531392e-01, -8.33861438e-03,\n",
              "           1.68913535e-01, -4.22982495e-02],\n",
              "         [ 1.07618328e-01,  1.17916173e-01, -7.72195800e-02,\n",
              "           2.71594311e-02, -8.52353055e-03,  1.53252159e-01,\n",
              "          -2.09124357e-01, -1.34727209e-01,  2.15167369e-01,\n",
              "          -2.58059950e-01,  1.78162968e-01,  3.72400511e-01,\n",
              "          -1.26280391e-02,  1.71273259e-01, -2.06038036e-01,\n",
              "          -3.57814608e-01, -8.80155911e-02,  1.55462249e-01,\n",
              "          -2.21259883e-01, -2.30450294e-01],\n",
              "         [ 3.06567716e-02, -1.78187025e-01, -1.65054395e-01,\n",
              "          -7.19565413e-02,  4.18930899e-02, -3.17584880e-01,\n",
              "          -8.56283176e-02,  1.01565152e-02, -4.01801858e-01,\n",
              "          -3.12417440e-01,  2.51564784e-01,  6.34669943e-02,\n",
              "           1.07772070e-01,  3.97762471e-01,  1.70155548e-01,\n",
              "          -1.50426377e-02, -3.79870953e-01, -9.96274470e-02,\n",
              "           2.00215470e-01, -2.62021816e-01],\n",
              "         [ 2.82400407e-01,  3.93086126e-02,  2.93200620e-01,\n",
              "          -3.38365694e-02,  1.05889428e-01, -1.25532341e-01,\n",
              "           3.59689862e-02,  4.73749474e-01, -2.02962778e-01,\n",
              "           3.65147385e-01, -2.04737324e-01,  8.17884410e-02,\n",
              "          -1.89176407e-01,  1.36133330e-01, -7.52466384e-02,\n",
              "           6.02028706e-02, -1.38404880e-01,  9.05135100e-02,\n",
              "          -1.61388073e-01,  9.71058405e-03],\n",
              "         [ 4.06053847e-02,  1.99007990e-01, -5.33095336e-02,\n",
              "          -4.18566507e-01,  6.45586705e-01,  6.22012515e-02,\n",
              "           4.14283591e-02, -4.00114781e-02, -2.87579990e-01,\n",
              "           1.96414684e-01, -1.28386755e-02,  8.47140747e-02,\n",
              "          -1.84638692e-01, -3.55732443e-01,  1.87225222e-01,\n",
              "          -1.47154070e-01,  2.87594560e-01,  8.78654022e-02,\n",
              "          -1.74208062e-01, -2.44910939e-01],\n",
              "         [ 8.08328903e-02,  1.96888748e-01, -4.79341460e-01,\n",
              "           1.87609574e-01,  5.55112268e-01,  8.20245808e-02,\n",
              "           3.47155057e-01,  2.68351613e-01, -1.92239079e-01,\n",
              "           9.78929890e-02, -1.73774259e-01, -1.33367081e-01,\n",
              "           1.04220147e-01, -3.06188287e-01, -4.42051823e-01,\n",
              "           1.82183747e-01, -2.75457905e-01, -3.82228100e-01,\n",
              "          -9.67579205e-03, -1.88081952e-01],\n",
              "         [-8.75603351e-02,  1.60778310e-01, -3.03094457e-01,\n",
              "          -1.44271249e-01, -4.56954957e-02, -1.24037769e-01,\n",
              "          -2.94238226e-01, -1.26277703e-01, -1.73745039e-02,\n",
              "          -2.93742572e-01,  1.99052281e-01, -2.76851650e-01,\n",
              "          -1.05081285e-01, -9.99665540e-02, -2.46525213e-01,\n",
              "           5.45481368e-01,  3.18422866e-01, -1.50373771e-01,\n",
              "          -1.35523712e-01,  1.26473491e-01],\n",
              "         [-8.11182014e-02, -2.10631787e-01, -3.45431750e-02,\n",
              "          -7.70179375e-02,  8.33669222e-02, -1.70979262e-01,\n",
              "          -2.54260004e-01,  1.09524146e-01,  2.39909247e-01,\n",
              "           2.79028541e-01,  2.06528982e-01,  3.35610555e-01,\n",
              "           2.95622529e-01, -1.82952809e-01, -4.19976186e-01,\n",
              "           1.93514524e-01,  1.20055133e-01,  1.29411137e-01,\n",
              "           3.24868928e-01, -2.12440329e-02],\n",
              "         [ 8.67730021e-02, -6.15105753e-02,  1.98164413e-02,\n",
              "           1.02735318e-01,  7.02217350e-02,  1.64784675e-01,\n",
              "           3.69794636e-01, -1.39830355e-01, -7.81277899e-03,\n",
              "           2.44016620e-01,  2.31781074e-02,  2.69959238e-01,\n",
              "           5.23179173e-02, -1.72907191e-01, -2.31211048e-01,\n",
              "           1.43045888e-01, -8.00303920e-02,  1.31748705e-01,\n",
              "           1.07567790e-01,  1.94295156e-01],\n",
              "         [ 1.12688995e-01, -1.72450985e-01,  1.77225825e-02,\n",
              "           5.67308683e-02, -5.77776059e-03, -3.65531105e-01,\n",
              "          -8.93143961e-02, -1.19510493e-02, -4.91806543e-02,\n",
              "           3.18626259e-01,  4.08693082e-01,  7.97711843e-02,\n",
              "           2.00504229e-01,  6.00887991e-04, -4.06142669e-02,\n",
              "           7.11323839e-02,  1.04085557e-01, -4.55014764e-01,\n",
              "          -2.39666846e-01, -2.66555766e-01],\n",
              "         [ 2.11718227e-01, -1.07821969e-01, -2.99491953e-01,\n",
              "           2.47767798e-01, -1.48674812e-01, -1.38117902e-01,\n",
              "           1.18695122e-02,  1.22138984e-01, -2.00925949e-01,\n",
              "          -1.76052054e-01, -1.48934037e-03, -9.79308090e-02,\n",
              "          -1.94019927e-01,  3.24056210e-01, -2.71400442e-02,\n",
              "           1.38245979e-01,  1.77923212e-01, -1.24695936e-02,\n",
              "           2.47445244e-01,  4.84833984e-03],\n",
              "         [-7.92621186e-02,  1.11419082e-01,  3.32017556e-01,\n",
              "           2.40743785e-01,  2.46035527e-01, -3.85737578e-01,\n",
              "           1.40762948e-01, -3.34235254e-01, -4.83114763e-01,\n",
              "          -3.15191967e-02,  2.54662908e-01,  1.04648968e-01,\n",
              "           5.45285764e-01,  7.13998409e-02,  5.10310787e-02,\n",
              "          -4.63068598e-02, -1.75214342e-01,  1.95137678e-01,\n",
              "          -1.62319734e-01, -2.00168545e-02],\n",
              "         [-2.01426277e-01,  2.98372312e-02,  1.34695387e-01,\n",
              "           4.74778398e-03, -3.15298621e-01,  2.39612053e-01,\n",
              "           1.60148963e-01,  7.67655686e-03, -7.86693108e-03,\n",
              "           2.21820229e-01,  3.36452533e-01, -5.35461146e-01,\n",
              "          -1.38371210e-01, -9.16468953e-02, -1.65479219e-01,\n",
              "          -1.49827532e-01,  3.45107065e-01, -3.04297413e-01,\n",
              "           1.82697851e-01, -2.06467853e-01],\n",
              "         [ 2.73029315e-01, -1.07895749e-02,  6.01264183e-02,\n",
              "           1.36404266e-01, -2.08945822e-01, -2.03028184e-01,\n",
              "          -1.32014477e-01, -1.82426140e-01, -1.16237229e-01,\n",
              "           8.86801403e-02, -2.56242277e-01,  4.76874719e-02,\n",
              "          -1.70391082e-01, -5.86042997e-02,  3.18442045e-01,\n",
              "          -3.65564029e-01,  1.13960404e-02,  6.39410317e-02,\n",
              "           3.51061083e-02, -7.79031713e-02],\n",
              "         [ 4.28338684e-02, -7.24017622e-02, -3.31503758e-01,\n",
              "          -3.58652621e-01,  1.30311546e-01,  2.71594987e-01,\n",
              "          -5.97327218e-02,  1.02074044e-01, -3.51057313e-01,\n",
              "          -1.24645560e-01, -8.16221505e-02, -2.33895938e-01,\n",
              "           2.99321761e-01,  9.63292494e-02,  2.07692901e-03,\n",
              "          -3.64824419e-01,  9.15350834e-02, -6.82151374e-02,\n",
              "          -1.49100019e-01, -5.26543604e-02],\n",
              "         [-9.06147182e-02, -2.96631179e-01,  2.63846734e-01,\n",
              "           9.63639830e-02, -7.47061223e-02, -4.24762504e-02,\n",
              "          -9.18555196e-02,  3.63360399e-01, -1.01907008e-01,\n",
              "          -2.18362359e-01,  7.08541588e-03,  1.75990746e-01,\n",
              "          -1.62073833e-01, -2.40547401e-02, -3.74102209e-02,\n",
              "           2.64451480e-01, -2.77661530e-01, -2.31461207e-02,\n",
              "           5.09010374e-02, -1.97110172e-01],\n",
              "         [ 3.71493371e-02,  1.15781926e-01, -3.77690136e-02,\n",
              "           3.57567792e-01,  3.17035807e-02, -2.66164692e-01,\n",
              "           5.13682229e-02,  2.90332461e-01,  1.40739169e-01,\n",
              "          -1.06691934e-01, -7.43230701e-02, -1.81665770e-02,\n",
              "          -2.47024337e-01, -3.71919771e-01,  1.90335009e-01,\n",
              "          -2.18258054e-02, -1.01692765e-02,  1.87555146e-02,\n",
              "           2.38673951e-01,  4.13989317e-01],\n",
              "         [-3.39584925e-02, -1.31227373e-01,  9.17428463e-02,\n",
              "           2.11358190e-01,  2.92259787e-01,  1.74708109e-01,\n",
              "           2.69847065e-01, -8.07833134e-02,  1.50694681e-01,\n",
              "          -5.46052538e-02,  1.75847763e-01,  2.41179175e-01,\n",
              "          -2.65934227e-01,  3.20852416e-02, -3.13591999e-01,\n",
              "          -2.62590637e-01,  1.02060247e-01, -1.59276254e-02,\n",
              "          -1.87147194e-01,  4.97229400e-01],\n",
              "         [ 2.06465437e-01, -3.65089472e-02, -2.56870100e-01,\n",
              "           2.30190233e-01, -1.17452490e-02,  1.71349154e-01,\n",
              "           1.85096252e-01,  2.87132013e-01,  2.11474245e-01,\n",
              "           3.78091068e-01,  1.39679938e-01,  1.55078967e-01,\n",
              "           3.02450008e-01, -8.85935358e-02, -2.26115607e-01,\n",
              "          -5.27948258e-02,  2.35617229e-01,  1.08021483e-01,\n",
              "          -2.84003693e-01,  1.48590467e-01]]),\n",
              "  array([[-9.35742496e-02,  2.58955154e-01, -4.49589437e-01,\n",
              "          -3.87775285e-01, -2.49496700e-01, -2.24579807e-02,\n",
              "           4.09344451e-02, -4.27408803e-01,  4.79179353e-02,\n",
              "          -4.49114476e-01],\n",
              "         [ 1.57937091e-01, -1.23777256e-01,  6.18424922e-02,\n",
              "          -1.28758271e-01,  1.14656453e-01,  1.24545922e-01,\n",
              "          -4.89855313e-01, -1.42841603e-01, -3.64665532e-02,\n",
              "           3.22190717e-01],\n",
              "         [-7.21371667e-02,  1.07685384e-01, -6.79819462e-02,\n",
              "          -7.11606323e-02,  1.00344825e-01,  1.01458561e-01,\n",
              "          -1.66198998e-01,  5.35629611e-01,  1.99775648e-01,\n",
              "           1.03634193e-01],\n",
              "         [-1.22865825e-01,  4.64928848e-04,  2.22472189e-01,\n",
              "           8.23670200e-02, -9.63872438e-02,  2.64086646e-01,\n",
              "           2.59646380e-02, -1.27723350e-01, -2.53606517e-02,\n",
              "           1.16044993e-01],\n",
              "         [ 5.25291829e-02,  8.23801068e-04, -9.60853738e-02,\n",
              "           1.01396782e-01,  1.49287619e-01, -1.69388850e-01,\n",
              "          -1.69998246e-01,  1.49340902e-01, -1.41780347e-01,\n",
              "          -1.79969222e-01],\n",
              "         [ 2.60621296e-01,  5.16086024e-02,  5.34000517e-01,\n",
              "           1.56713724e-01, -4.27375881e-01,  1.38914640e-01,\n",
              "           1.75027626e-01, -2.51793112e-01,  4.50791956e-02,\n",
              "           8.66692628e-02],\n",
              "         [ 1.93162455e-01,  3.74243545e-01, -1.55132652e-01,\n",
              "          -2.42686783e-01, -1.65130757e-01, -8.65555755e-02,\n",
              "           1.75847959e-01, -3.69927091e-02, -1.45370867e-01,\n",
              "           1.56907405e-01],\n",
              "         [-2.21367209e-01, -1.91756086e-01,  1.60666888e-01,\n",
              "          -9.26714498e-02, -3.36888468e-01, -2.18394059e-01,\n",
              "          -2.19469826e-01, -2.10598648e-01, -2.37911189e-01,\n",
              "          -1.51739799e-01],\n",
              "         [ 1.03150275e-01,  1.83202875e-01, -3.24349152e-01,\n",
              "           6.28711261e-02,  3.26068789e-01, -1.14075178e-01,\n",
              "          -4.04474197e-02,  6.70955609e-02,  3.70036435e-01,\n",
              "           1.56629175e-01],\n",
              "         [ 5.64649511e-01, -3.58633834e-01, -3.70239411e-01,\n",
              "           1.06508842e-01, -1.15646726e-01,  2.27839447e-01,\n",
              "           2.11655732e-01,  9.23972461e-02, -2.67373456e-02,\n",
              "           1.08645162e-01],\n",
              "         [-1.75392129e-01, -3.65955729e-01, -5.64626546e-02,\n",
              "          -2.59805591e-02,  1.03348742e-01, -4.33509714e-02,\n",
              "           2.20880485e-01,  1.96368332e-01,  2.11821437e-02,\n",
              "          -1.36505813e-01],\n",
              "         [ 2.88119090e-01,  4.24864615e-01, -1.44972747e-01,\n",
              "           1.08577950e-01, -5.28696878e-02,  1.16938740e-01,\n",
              "          -9.94955775e-02,  4.40106516e-01,  4.73457997e-01,\n",
              "          -1.98639660e-01],\n",
              "         [-9.67403228e-02, -1.46280929e-01,  7.50912786e-01,\n",
              "           2.43684263e-01, -9.16955447e-02, -1.67490635e-01,\n",
              "          -3.67558509e-01,  3.73395328e-02, -2.73809832e-01,\n",
              "          -3.67970578e-01],\n",
              "         [-2.73115642e-01,  4.46159587e-02,  3.84940784e-01,\n",
              "           3.68420198e-01,  2.82845053e-02,  3.50600928e-01,\n",
              "          -2.07160609e-01, -2.32633509e-01,  5.85923720e-02,\n",
              "           4.04699865e-01],\n",
              "         [ 1.41374615e-02, -3.51838917e-01, -1.05029970e-01,\n",
              "          -4.38242260e-01,  3.76213661e-01, -2.87787774e-01,\n",
              "           1.43164876e-01, -1.48679417e-01, -1.10006998e-01,\n",
              "           2.22375864e-01],\n",
              "         [ 3.83896156e-01, -6.64663819e-02,  1.63296185e-01,\n",
              "           1.38518058e-01,  1.67078191e-01,  8.39937587e-02,\n",
              "          -1.52242590e-01,  1.66726505e-01, -2.93511288e-01,\n",
              "           7.56662248e-02],\n",
              "         [-4.63225215e-01,  4.03177097e-01,  9.64874814e-02,\n",
              "          -1.81551829e-01, -2.43216933e-01, -1.17625302e-01,\n",
              "           3.79686262e-01, -1.23392651e-01, -1.48594440e-01,\n",
              "          -1.01392050e-01],\n",
              "         [-1.30517768e-01, -9.60810656e-02, -2.23646021e-01,\n",
              "           1.08694097e-01, -5.93720431e-02, -5.58281867e-02,\n",
              "           2.16451153e-01, -2.84403455e-02,  3.77087885e-01,\n",
              "          -9.85408276e-02],\n",
              "         [-3.41478439e-01, -2.01324328e-01, -1.35251634e-02,\n",
              "          -2.57669538e-01,  6.00774745e-02, -2.57430742e-01,\n",
              "           1.58306175e-01, -3.71814137e-01, -1.60834849e-01,\n",
              "           7.02571888e-02],\n",
              "         [-1.96272021e-01, -1.33115358e-01, -4.17626399e-01,\n",
              "           1.03319498e-01,  1.84953405e-01,  1.33618578e-02,\n",
              "          -2.86998385e-01, -5.57084294e-02,  1.74836279e-02,\n",
              "          -2.08064226e-02]])),\n",
              " (array([[-2.57964085e-04,  1.09639665e-04, -8.89817944e-04,\n",
              "           9.28960937e-05, -7.36435567e-04, -6.30901927e-04,\n",
              "          -1.26271465e-03,  1.04230978e-04, -4.31273271e-04,\n",
              "          -4.97030714e-04, -8.49090300e-04,  5.00440541e-04,\n",
              "          -6.84036268e-04, -7.07918460e-04,  2.04712566e-04,\n",
              "          -1.56659818e-03, -1.79646456e-04,  1.00180941e-04,\n",
              "           1.65464235e-04, -5.32661105e-04]]),\n",
              "  array([[-3.73781096e-03,  6.40221032e-03, -1.57319540e-03,\n",
              "          -1.95922102e-03, -3.74685640e-03,  4.84128631e-03,\n",
              "          -2.76283554e-03, -2.90064322e-04, -2.79193251e-04,\n",
              "          -2.03814822e-04, -3.47640781e-04,  1.05933549e-05,\n",
              "          -4.64573786e-03,  2.48619246e-03,  3.22635127e-03,\n",
              "           1.04996541e-03, -4.55992341e-04,  2.09837501e-03,\n",
              "          -3.89725682e-04, -2.14573505e-03]]),\n",
              "  array([[ 0.00561885, -0.02557285, -0.00418723, -0.01709847, -0.00044874,\n",
              "          -0.01147787,  0.01670374, -0.00824989,  0.0070792 , -0.01255711,\n",
              "          -0.00082148, -0.00216482, -0.01941762, -0.02843636,  0.00962883,\n",
              "          -0.0125503 ,  0.02078585,  0.00267736,  0.00702355, -0.0108193 ]]),\n",
              "  array([[-0.01345313,  0.09105676, -0.04515689, -0.02279771,  0.01752757,\n",
              "          -0.16287632,  0.11619457,  0.03519105, -0.02602814,  0.01034223]])))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "np.random.seed(100000)\n",
        "\n",
        "# One hot encoding the labels into 10 classes\n",
        "Y_class = np.array([(i)*[0]+[1]+(9-i)*[0] for i in Y])\n",
        "\n",
        "# Defining the sigmoid activation function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Defininf  the softmax function\n",
        "def softmax(z):\n",
        "    exps = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "# Making random initialized weights and bias for all layers\n",
        "def initialize_weights(num_layers,n_hu):\n",
        "    layer_sizes = [784]+num_layers*[n_hu]+[10]\n",
        "    weight_bias = []\n",
        "    for i in range(len(layer_sizes)-1):\n",
        "        w = np.random.randn(layer_sizes[i], layer_sizes[i+1]) / np.sqrt(layer_sizes[i])\n",
        "        b = np.zeros((1, layer_sizes[i+1]))\n",
        "        weight_bias.append((w,b))\n",
        "    return weight_bias\n",
        "\n",
        "# forward pass\n",
        "def forward(x, weight):\n",
        "    acti = [x]\n",
        "    A = x\n",
        "    for w, b in weight:\n",
        "        z = np.dot(A, w) + b\n",
        "        A = sigmoid(z)\n",
        "        acti.append(A)\n",
        "    y_h = softmax(z)\n",
        "    return acti, y_h\n",
        "\n",
        "# backward pass\n",
        "def backward(x, y, acti, y_h,weight_bias, lamda):\n",
        "    m = x.shape[0]\n",
        "    dz = y_h - y\n",
        "    dw = np.dot(acti[-2].T, dz)/m + (lamda * weight_bias[-1][0])/m\n",
        "    db = np.sum(dz, axis=0, keepdims=True)/m\n",
        "    grad = [(dw, db)]\n",
        "    for i in range(len(weight_bias)-1, 0, -1):\n",
        "        dA = np.dot(dz, weight_bias[i][0].T)\n",
        "        dz = dA * acti[i] * (1 - acti[i])\n",
        "        dw = np.dot(acti[i-1].T, dz) / m + (lamda * weight_bias[i-1][0]) / m\n",
        "        db = np.sum(dz, axis=0, keepdims=True) / m\n",
        "        grad.insert(0, (dw, db))\n",
        "    return grad\n",
        "\n",
        "def update(weight_bias, grad, lr):\n",
        "    for i in range(len(weight_bias)):\n",
        "        w, b = weight_bias[i]\n",
        "        dw, db = grad[i]\n",
        "        w = w- lr*dw\n",
        "        b = b - lr* db\n",
        "        weight_bias[i] = (w, b)\n",
        "    return weight_bias\n",
        "\n",
        "def train(x, y,num_layer=3,n_hu=20, num_iter=100, lr=0.1,lamda=0.01):\n",
        "    weight_bias = initialize_weights(num_layer,n_hu)\n",
        "    for epoch in range(num_iter):\n",
        "        acti, y_h = forward(X, weight_bias)\n",
        "        grad = backward(x,y, acti, y_h, weight_bias,lamda)\n",
        "        weights = update(weight_bias, grad, lr)\n",
        "        cost = -np.sum(y * np.log(y_h)) / x.shape[0]\n",
        "        if epoch % 10 == 0:\n",
        "            print(\"Epoch {}: loss = {}\".format(epoch, cost))\n",
        "\n",
        "    weigh = list(zip(*weights))[0]\n",
        "    bia = list(zip(*weights))[1]\n",
        "    return weigh,bia\n",
        "\n",
        "num_layer=3 # Number of layers\n",
        "n_hu=20 # number of hidden units\n",
        "train(X,Y_class,3,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5\n",
        "\n",
        "Extend your code from problem 4 to implement different activations functions which will be  passed as a parameter. In this problem all activations (except the final layer which should remain a  softmax) must be changed to the passed activation function."
      ],
      "metadata": {
        "id": "rWqwcGDiY4p4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANSWER 5"
      ],
      "metadata": {
        "id": "-7oMijL2XQLo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XH6xCGcf7yVW",
        "outputId": "e1e4b03b-c488-4012-e86c-59e6e6cf15b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 2.31581705892741\n",
            "Epoch 10: loss = 2.3084567546673544\n",
            "Epoch 20: loss = 2.30250805329236\n",
            "Epoch 30: loss = 2.2974877995018264\n",
            "Epoch 40: loss = 2.2930880059302416\n",
            "Epoch 50: loss = 2.2891039620862483\n",
            "Epoch 60: loss = 2.2853918920046237\n",
            "Epoch 70: loss = 2.281852707066694\n",
            "Epoch 80: loss = 2.278414036192011\n",
            "Epoch 90: loss = 2.2750200076842044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[ 0.00256273, -0.06600515,  0.05410779, ..., -0.02042694,\n",
              "          -0.02588275,  0.07300673],\n",
              "         [-0.06792583, -0.03998851,  0.00957879, ...,  0.01156511,\n",
              "           0.02280227,  0.04486038],\n",
              "         [ 0.04719391, -0.01432991,  0.04285393, ...,  0.00844747,\n",
              "           0.00151294,  0.04007569],\n",
              "         ...,\n",
              "         [ 0.00047193,  0.05446774, -0.07609704, ..., -0.04234888,\n",
              "          -0.03934672, -0.01621983],\n",
              "         [ 0.03255095,  0.05758201,  0.10453215, ..., -0.01574548,\n",
              "          -0.02864816,  0.07133386],\n",
              "         [-0.06647086, -0.03183223,  0.01672802, ...,  0.02687025,\n",
              "           0.01034864,  0.01300802]]),\n",
              "  array([[ 0.21070543, -0.1750123 ,  0.40045918,  0.06501277, -0.14409772,\n",
              "          -0.00622635, -0.09408295, -0.409992  , -0.36268119, -0.42870973,\n",
              "           0.08364539, -0.3040264 , -0.13741099,  0.20733159,  0.1611186 ,\n",
              "          -0.01543212, -0.01626995, -0.23583664,  0.1019906 ,  0.32089352],\n",
              "         [ 0.21232411,  0.22071442,  0.25728042,  0.23033051,  0.05448814,\n",
              "           0.20004993,  0.03097763,  0.06748179,  0.05670505,  0.20611178,\n",
              "          -0.31853092, -0.33629089, -0.02603939,  0.04846234, -0.13058533,\n",
              "          -0.07371507,  0.06864102, -0.04625446, -0.07584736, -0.1311741 ],\n",
              "         [-0.30857957, -0.1221901 , -0.04488225, -0.18415173,  0.04908387,\n",
              "           0.25955038,  0.16482873,  0.42642561,  0.11994035,  0.38635628,\n",
              "           0.01444298, -0.24681622,  0.79560547, -0.07881712, -0.42702429,\n",
              "          -0.13245329,  0.18139489,  0.05781498,  0.02749522, -0.08507865],\n",
              "         [ 0.23481344,  0.32612356,  0.08590674, -0.06109825, -0.21541906,\n",
              "          -0.02495941,  0.00599714,  0.10297457, -0.31829912,  0.00353252,\n",
              "           0.11567846,  0.24661645,  0.44124692,  0.02022627, -0.09036767,\n",
              "           0.08416858,  0.28813126,  0.28671024,  0.22914366, -0.15391759],\n",
              "         [ 0.18971437, -0.30313355, -0.02319361,  0.17028143, -0.11186965,\n",
              "           0.11769556, -0.13439436, -0.24042412,  0.29483073,  0.09907679,\n",
              "           0.27572507,  0.42924814,  0.07981974, -0.20577512, -0.28571645,\n",
              "          -0.14793459,  0.16584714, -0.13408896,  0.48627688,  0.05376307],\n",
              "         [ 0.04692734,  0.24649823, -0.08238444,  0.2117805 , -0.29427696,\n",
              "          -0.4440206 ,  0.32209842,  0.12961922,  0.23669347,  0.22344959,\n",
              "          -0.16491512, -0.34134326,  0.05366545,  0.2198321 , -0.17412088,\n",
              "          -0.1584223 , -0.01689507, -0.51643675, -0.05079463,  0.05619885],\n",
              "         [-0.21705091, -0.20148539,  0.03862557,  0.63448578,  0.28755252,\n",
              "           0.10358104, -0.28086969,  0.10123281,  0.22952856, -0.18046213,\n",
              "          -0.13394805,  0.33506158,  0.20771253, -0.40148679, -0.22042203,\n",
              "           0.11795295,  0.38685734, -0.26212179,  0.00889389,  0.22993573],\n",
              "         [ 0.50109608,  0.3090712 , -0.17348219, -0.15634604, -0.14347692,\n",
              "          -0.28867644,  0.18899381,  0.02316208,  0.48936455, -0.18560417,\n",
              "          -0.21429765,  0.46733217,  0.03913903,  0.07584608,  0.30296645,\n",
              "           0.1907714 ,  0.13875296,  0.17245886, -0.38518273,  0.03768735],\n",
              "         [-0.06534767,  0.01240221, -0.08843985,  0.08326646,  0.46239278,\n",
              "          -0.15735755, -0.36708887,  0.00506481,  0.104891  ,  0.13839332,\n",
              "           0.34284884, -0.35291062, -0.0393055 ,  0.11460618, -0.2326381 ,\n",
              "           0.2088119 ,  0.32361314,  0.13539481,  0.13164796,  0.12593993],\n",
              "         [ 0.401014  , -0.22491107,  0.16584393, -0.11236923,  0.19565374,\n",
              "           0.07848901,  0.19941181,  0.10129248,  0.1256644 , -0.02359408,\n",
              "          -0.10459203,  0.13447126, -0.10812523, -0.09608922, -0.0268105 ,\n",
              "           0.1986598 ,  0.03506549,  0.0126439 ,  0.47772231, -0.30272036],\n",
              "         [ 0.10445066,  0.06820192,  0.23471852, -0.04579016,  0.22099343,\n",
              "          -0.35918694, -0.27275174, -0.04709332,  0.04543332,  0.27303024,\n",
              "          -0.02041308, -0.46735206,  0.10889795, -0.27750134, -0.21068661,\n",
              "          -0.01583714,  0.1105617 ,  0.15207013,  0.36659001, -0.09325273],\n",
              "         [-0.58281645, -0.16632118, -0.26894917,  0.13898899,  0.22676069,\n",
              "           0.12664926, -0.01618926, -0.08336466,  0.10174341,  0.12050399,\n",
              "          -0.29138412, -0.01574765, -0.01974669, -0.24811612,  0.15766502,\n",
              "          -0.34511496, -0.14428121,  0.19363067,  0.10957353, -0.18724274],\n",
              "         [ 0.10334809, -0.07840406, -0.03641798,  0.3015968 , -0.12462675,\n",
              "          -0.2448306 , -0.02151602,  0.13024947, -0.14480748,  0.17497519,\n",
              "           0.10663685, -0.05959195, -0.06608367,  0.04816549, -0.17325951,\n",
              "           0.00428045, -0.11709332, -0.02969655, -0.37293418,  0.25765243],\n",
              "         [-0.13325521, -0.2433829 , -0.14015651,  0.05052554, -0.13949914,\n",
              "          -0.44925857,  0.01623916,  0.18108146, -0.24298985,  0.23921292,\n",
              "          -0.36648781,  0.15992425, -0.1357204 , -0.31038121, -0.27063582,\n",
              "          -0.50898329, -0.04873254,  0.21750191,  0.09040968, -0.11131212],\n",
              "         [ 0.09096562,  0.15855833,  0.04158107,  0.35802417, -0.07659756,\n",
              "           0.0518236 ,  0.45646563, -0.00686464,  0.27007916,  0.37465084,\n",
              "          -0.05089221, -0.1466684 , -0.19776505,  0.01295166,  0.31835346,\n",
              "          -0.14995621, -0.33663497,  0.13011219,  0.14536274, -0.19467741],\n",
              "         [ 0.7068935 ,  0.01660901,  0.22087291,  0.36837159, -0.02361904,\n",
              "          -0.26015977,  0.10773962,  0.1897571 ,  0.24242054, -0.12527488,\n",
              "           0.10225801,  0.13043593,  0.11730563,  0.72087   , -0.11428997,\n",
              "           0.01916688,  0.03192365,  0.07294551, -0.17811547,  0.26993315],\n",
              "         [ 0.14154088, -0.00624279, -0.37404495,  0.04509098,  0.27457148,\n",
              "          -0.20237997, -0.3638646 ,  0.05076887,  0.28850486, -0.06333941,\n",
              "          -0.13263093,  0.02001288,  0.04189253,  0.06833318,  0.3338692 ,\n",
              "          -0.33537202, -0.09399286, -0.34127912,  0.03867952, -0.1937537 ],\n",
              "         [-0.05683633, -0.07156676,  0.00325559, -0.06238762,  0.00129301,\n",
              "           0.10981819, -0.20649958,  0.13271062, -0.00855744,  0.24407287,\n",
              "          -0.05727222,  0.29131693, -0.0135214 , -0.15668019, -0.21930728,\n",
              "          -0.37779599,  0.14484068,  0.25993553,  0.17962054,  0.04246613],\n",
              "         [-0.15757801,  0.14162532,  0.06158628, -0.12355271,  0.32820233,\n",
              "          -0.16707146,  0.33067259,  0.20083428,  0.15279831,  0.1918819 ,\n",
              "          -0.33549049, -0.2135589 , -0.13179672, -0.20213665,  0.22934577,\n",
              "          -0.19227826,  0.07955493,  0.17234608,  0.17840901, -0.47516454],\n",
              "         [ 0.52973616,  0.06929883, -0.17891625, -0.22131238,  0.01750676,\n",
              "           0.21795527,  0.22404257, -0.13417388,  0.35630641,  0.16372961,\n",
              "          -0.03130447,  0.08036858,  0.10586858,  0.06472954,  0.12220586,\n",
              "          -0.52524492,  0.04856084, -0.09354906,  0.0688582 , -0.01816887]]),\n",
              "  array([[-1.00530081e-01,  1.52783214e-01,  1.54167244e-01,\n",
              "           7.76865554e-02,  8.35613408e-02, -2.99776751e-01,\n",
              "          -3.79672462e-01,  3.26404617e-01,  1.69984876e-01,\n",
              "           6.91268760e-03, -1.87878009e-01, -1.47465239e-01,\n",
              "           5.67650374e-02,  6.65217632e-02,  1.90752330e-02,\n",
              "           4.81863348e-01,  2.46293780e-01, -3.05805387e-01,\n",
              "           2.60476644e-01,  3.68969555e-01],\n",
              "         [-3.50113256e-01,  3.04341059e-02,  8.39490839e-02,\n",
              "          -5.60172963e-01,  4.09369874e-01,  1.89747426e-01,\n",
              "          -2.76505461e-01, -4.52348074e-01, -1.90301802e-01,\n",
              "           1.62339244e-01, -3.29475499e-01, -2.49958091e-01,\n",
              "          -2.83535003e-01, -1.93071908e-01,  2.74495410e-01,\n",
              "          -4.33125632e-01,  1.78894985e-01, -9.53475572e-03,\n",
              "           1.70706803e-01, -3.21790717e-02],\n",
              "         [ 1.05820587e-01,  1.30257163e-01, -7.52523745e-02,\n",
              "           3.35379047e-02, -7.10842886e-03,  1.58411932e-01,\n",
              "          -2.17226398e-01, -1.31226589e-01,  2.12165157e-01,\n",
              "          -2.51335532e-01,  1.81515123e-01,  3.74768286e-01,\n",
              "          -2.22921598e-03,  1.83272048e-01, -2.11393624e-01,\n",
              "          -3.49275664e-01, -9.90952920e-02,  1.54608983e-01,\n",
              "          -2.22455413e-01, -2.25487243e-01],\n",
              "         [ 2.74332313e-02, -1.62322935e-01, -1.61554832e-01,\n",
              "          -6.25443728e-02,  4.31750072e-02, -3.08568897e-01,\n",
              "          -9.59129710e-02,  1.60285642e-02, -4.07560871e-01,\n",
              "          -3.08362855e-01,  2.56213239e-01,  6.52180646e-02,\n",
              "           1.21907819e-01,  4.14460900e-01,  1.65018795e-01,\n",
              "          -9.95466603e-03, -3.89795573e-01, -1.01343748e-01,\n",
              "           2.03156828e-01, -2.53899896e-01],\n",
              "         [ 2.78851639e-01,  5.28447535e-02,  2.86900813e-01,\n",
              "          -2.38427924e-02,  1.07451708e-01, -1.19305010e-01,\n",
              "           2.63316047e-02,  4.81076557e-01, -2.08820254e-01,\n",
              "           3.74779765e-01, -2.10991757e-01,  8.71950414e-02,\n",
              "          -1.77302903e-01,  1.52703840e-01, -8.05620357e-02,\n",
              "           6.02409920e-02, -1.43225698e-01,  8.83232260e-02,\n",
              "          -1.57837138e-01,  1.32562809e-02],\n",
              "         [ 3.92264844e-02,  2.06148748e-01, -5.29778028e-02,\n",
              "          -4.12411564e-01,  6.45707860e-01,  6.80600794e-02,\n",
              "           3.62215993e-02, -3.68308322e-02, -2.91235038e-01,\n",
              "           2.00114485e-01, -1.22835724e-02,  8.46807019e-02,\n",
              "          -1.77043578e-01, -3.46472011e-01,  1.83582417e-01,\n",
              "          -1.42886552e-01,  2.82015310e-01,  8.71358019e-02,\n",
              "          -1.75721180e-01, -2.42601892e-01],\n",
              "         [ 7.86242942e-02,  2.09804556e-01, -4.76487314e-01,\n",
              "           1.94669183e-01,  5.56434579e-01,  9.08754676e-02,\n",
              "           3.37982280e-01,  2.69636081e-01, -1.96464461e-01,\n",
              "           1.04383845e-01, -1.71255440e-01, -1.30369952e-01,\n",
              "           1.14121360e-01, -2.91601633e-01, -4.50340301e-01,\n",
              "           1.90319423e-01, -2.87966502e-01, -3.82514681e-01,\n",
              "          -8.58623873e-03, -1.80205665e-01],\n",
              "         [-9.13658163e-02,  1.75525553e-01, -3.01792644e-01,\n",
              "          -1.34041394e-01, -4.54734543e-02, -1.16415355e-01,\n",
              "          -3.04368137e-01, -1.21231212e-01, -2.23342751e-02,\n",
              "          -2.90953829e-01,  2.00097043e-01, -2.74849915e-01,\n",
              "          -9.22115538e-02, -8.24392680e-02, -2.53432988e-01,\n",
              "           5.49053819e-01,  3.10344566e-01, -1.51830146e-01,\n",
              "          -1.30400877e-01,  1.33632744e-01],\n",
              "         [-8.56790323e-02, -1.94563411e-01, -3.32582208e-02,\n",
              "          -6.80686278e-02,  8.38365045e-02, -1.61322674e-01,\n",
              "          -2.66777219e-01,  1.14396318e-01,  2.33053792e-01,\n",
              "           2.76615627e-01,  2.07056748e-01,  3.38382979e-01,\n",
              "           3.09329001e-01, -1.62239956e-01, -4.27037332e-01,\n",
              "           1.92047302e-01,  1.16233592e-01,  1.28040876e-01,\n",
              "           3.37623491e-01, -1.39417159e-02],\n",
              "         [ 8.20491072e-02, -4.38768806e-02,  1.78024446e-02,\n",
              "           1.15045005e-01,  7.12133019e-02,  1.73518135e-01,\n",
              "           3.57960337e-01, -1.33341397e-01, -1.39552442e-02,\n",
              "           2.55200525e-01,  2.12156811e-02,  2.72508132e-01,\n",
              "           6.51419548e-02, -1.54478496e-01, -2.37313996e-01,\n",
              "           1.52488106e-01, -9.36155891e-02,  1.30412222e-01,\n",
              "           1.08433336e-01,  2.01589051e-01],\n",
              "         [ 1.10111847e-01, -1.62404043e-01,  1.88363739e-02,\n",
              "           6.24469500e-02, -4.07049043e-03, -3.64021581e-01,\n",
              "          -9.52613520e-02, -9.53716962e-03, -5.09803937e-02,\n",
              "           3.25986903e-01,  4.05184089e-01,  8.24551807e-02,\n",
              "           2.05809942e-01,  1.06792345e-02, -4.13653176e-02,\n",
              "           7.34915544e-02,  9.61226728e-02, -4.56447482e-01,\n",
              "          -2.44555480e-01, -2.59970474e-01],\n",
              "         [ 2.10752351e-01, -9.50340209e-02, -2.97537615e-01,\n",
              "           2.54861914e-01, -1.48253795e-01, -1.28544053e-01,\n",
              "           5.20565733e-03,  1.25020895e-01, -2.05588538e-01,\n",
              "          -1.68571841e-01, -4.02495521e-05, -9.70088946e-02,\n",
              "          -1.85237384e-01,  3.36498805e-01, -3.20738828e-02,\n",
              "           1.46971059e-01,  1.65249339e-01, -1.45477851e-02,\n",
              "           2.46036366e-01,  1.09749981e-02],\n",
              "         [-8.26584241e-02,  1.27509905e-01,  3.34789874e-01,\n",
              "           2.50576003e-01,  2.48730320e-01, -3.77939270e-01,\n",
              "           1.30539179e-01, -3.31746997e-01, -4.88628826e-01,\n",
              "          -2.69113030e-02,  2.54164066e-01,  1.07850129e-01,\n",
              "           5.55368112e-01,  8.90468930e-02,  4.56979069e-02,\n",
              "          -4.05715327e-02, -1.87590340e-01,  1.93715138e-01,\n",
              "          -1.58058408e-01, -6.75374750e-03],\n",
              "         [-2.02953739e-01,  3.98643584e-02,  1.45201685e-01,\n",
              "           5.60122773e-03, -3.14811326e-01,  2.44797232e-01,\n",
              "           1.52426179e-01,  7.05478143e-03, -1.18273498e-02,\n",
              "           2.14596715e-01,  3.42266274e-01, -5.31381140e-01,\n",
              "          -1.28689668e-01, -8.00047099e-02, -1.72250854e-01,\n",
              "          -1.56327996e-01,  3.43271568e-01, -3.06080816e-01,\n",
              "           1.94297272e-01, -1.95588225e-01],\n",
              "         [ 2.71221871e-01, -1.11303433e-03,  6.11995943e-02,\n",
              "           1.43201148e-01, -2.08743953e-01, -1.97050472e-01,\n",
              "          -1.38897864e-01, -1.79652449e-01, -1.19472476e-01,\n",
              "           9.33883201e-02, -2.56397895e-01,  4.96487402e-02,\n",
              "          -1.61925300e-01, -4.58585395e-02,  3.11707694e-01,\n",
              "          -3.61960179e-01,  3.99089052e-03,  6.25936496e-02,\n",
              "           3.33969659e-02, -7.34091637e-02],\n",
              "         [ 4.03782919e-02, -6.48375771e-02, -3.28544409e-01,\n",
              "          -3.54070800e-01,  1.30488566e-01,  2.71788083e-01,\n",
              "          -6.46911412e-02,  1.03719298e-01, -3.51247612e-01,\n",
              "          -1.23582641e-01, -8.12835465e-02, -2.33497606e-01,\n",
              "           3.02759127e-01,  1.05493329e-01,  4.34749477e-04,\n",
              "          -3.62897944e-01,  8.67673465e-02, -6.85592477e-02,\n",
              "          -1.49874459e-01, -4.78734877e-02],\n",
              "         [-9.42905143e-02, -2.79384121e-01,  2.62925546e-01,\n",
              "           1.07977348e-01, -7.10812792e-02, -3.52304205e-02,\n",
              "          -1.02103165e-01,  3.67284112e-01, -1.07352895e-01,\n",
              "          -2.06822464e-01,  2.81840841e-03,  1.81114727e-01,\n",
              "          -1.51538915e-01, -5.54023440e-03, -4.24591818e-02,\n",
              "           2.71029928e-01, -2.92112248e-01, -2.52450523e-02,\n",
              "           5.13173193e-02, -1.83711461e-01],\n",
              "         [ 3.55857185e-02,  1.29113871e-01, -3.73702382e-02,\n",
              "           3.68093204e-01,  3.14802853e-02, -2.57745342e-01,\n",
              "           4.23920541e-02,  2.95728567e-01,  1.35308876e-01,\n",
              "          -9.78229938e-02, -7.42393951e-02, -1.61925736e-02,\n",
              "          -2.35375173e-01, -3.56867810e-01,  1.83530089e-01,\n",
              "          -1.48186907e-02, -2.26456947e-02,  1.72619077e-02,\n",
              "           2.38332111e-01,  4.21825711e-01],\n",
              "         [-3.83254476e-02, -1.14697717e-01,  8.73819482e-02,\n",
              "           2.23312560e-01,  2.94470742e-01,  1.82372179e-01,\n",
              "           2.59283533e-01, -7.38424843e-02,  1.44372584e-01,\n",
              "          -3.92290255e-02,  1.72649749e-01,  2.45208830e-01,\n",
              "          -2.53808919e-01,  4.79217853e-02, -3.17431858e-01,\n",
              "          -2.53868693e-01,  8.77609238e-02, -1.80289264e-02,\n",
              "          -1.89257875e-01,  5.04226473e-01],\n",
              "         [ 2.04841350e-01, -2.54524471e-02, -2.51713537e-01,\n",
              "           2.35048135e-01, -1.07380895e-02,  1.74757955e-01,\n",
              "           1.78150899e-01,  2.90177898e-01,  2.09530400e-01,\n",
              "           3.83152976e-01,  1.42524907e-01,  1.56273234e-01,\n",
              "           3.10879366e-01, -7.76008411e-02, -2.28648796e-01,\n",
              "          -4.60865727e-02,  2.26689351e-01,  1.06821197e-01,\n",
              "          -2.89097382e-01,  1.54663825e-01]]),\n",
              "  array([[-0.06657013,  0.20684166, -0.42478782, -0.37571215, -0.26103131,\n",
              "           0.06176966, -0.02175797, -0.45095019,  0.05892984, -0.45834099],\n",
              "         [ 0.14377603, -0.1915994 ,  0.08152919, -0.13774792,  0.1320655 ,\n",
              "           0.18258926, -0.53193694, -0.11623332, -0.03086017,  0.32789145],\n",
              "         [-0.00096519,  0.10558686, -0.09313906, -0.02049808,  0.0542584 ,\n",
              "           0.1545796 , -0.25075669,  0.43916925,  0.28359156,  0.09922282],\n",
              "         [-0.07565599, -0.08989631,  0.20097533,  0.11942485, -0.13032655,\n",
              "           0.33840838, -0.07408813, -0.10515791, -0.00939909,  0.16477877],\n",
              "         [ 0.09966581, -0.0687919 , -0.08914682,  0.1284796 ,  0.17681146,\n",
              "          -0.04456981, -0.27437414,  0.06529765, -0.12046632, -0.17674928],\n",
              "         [ 0.26272579,  0.02116945,  0.54740416,  0.16513914, -0.43250579,\n",
              "           0.19469604,  0.13343618, -0.26197941,  0.05437971,  0.0850006 ],\n",
              "         [ 0.20804192,  0.33001938, -0.13450766, -0.23356772, -0.17375119,\n",
              "          -0.0145249 ,  0.12575587, -0.05346262, -0.13554727,  0.14983621],\n",
              "         [-0.20002684, -0.26362624,  0.15565057, -0.07245953, -0.35781033,\n",
              "          -0.21441734, -0.29718042, -0.18450805, -0.17397594, -0.11177572],\n",
              "         [ 0.10894723,  0.1500436 , -0.30766806,  0.06604659,  0.31737599,\n",
              "          -0.06363198, -0.07701632,  0.0718306 ,  0.37391547,  0.15033938],\n",
              "         [ 0.59077384, -0.35724817, -0.34986266,  0.11198181, -0.14421213,\n",
              "           0.25787276,  0.14713797,  0.05526291,  0.03221378,  0.09651852],\n",
              "         [-0.16492136, -0.40088285, -0.03974533,  0.00883717,  0.05986885,\n",
              "           0.02086899,  0.1328443 ,  0.20111286,  0.06480588, -0.14465665],\n",
              "         [ 0.39172276,  0.35751227, -0.11872632,  0.14723513, -0.08220548,\n",
              "           0.21221365, -0.17794122,  0.37820224,  0.47127275, -0.22319854],\n",
              "         [-0.11925032, -0.19302026,  0.76301525,  0.24256824, -0.08309404,\n",
              "          -0.11152618, -0.43221341,  0.08080978, -0.26726488, -0.35963395],\n",
              "         [-0.25258792, -0.01178079,  0.40034035,  0.39251861,  0.0211427 ,\n",
              "           0.41636534, -0.26192383, -0.23802386,  0.06769171,  0.39350253],\n",
              "         [ 0.01718283, -0.37646043, -0.09102242, -0.43078743,  0.37163871,\n",
              "          -0.2394154 ,  0.10739358, -0.16012843, -0.1031743 ,  0.21907981],\n",
              "         [ 0.30883189, -0.12838545,  0.16021704,  0.12442911,  0.21496953,\n",
              "           0.07835779, -0.21083892,  0.20353061, -0.23700787,  0.15285109],\n",
              "         [-0.52853315,  0.33968217,  0.11665129, -0.21763662, -0.23639102,\n",
              "          -0.10820849,  0.3576163 , -0.0375191 , -0.10782795, -0.077481  ],\n",
              "         [-0.12083075, -0.1347028 , -0.20399835,  0.11719836, -0.06659338,\n",
              "           0.00788102,  0.17178465, -0.0431982 ,  0.38602573, -0.1037594 ],\n",
              "         [-0.45419499, -0.27043184,  0.00101495, -0.30514266,  0.11904381,\n",
              "          -0.26553621,  0.12969074, -0.30332117, -0.10292912,  0.13637013],\n",
              "         [-0.17650137, -0.20819117, -0.40737794,  0.11462711,  0.17245082,\n",
              "           0.07585138, -0.35716853, -0.08041429,  0.04316798,  0.03214738]])),\n",
              " (array([[-2.82458917e-04,  1.44538215e-04, -8.96502497e-05,\n",
              "           5.72135855e-04,  4.34697130e-05, -3.82425976e-05,\n",
              "           1.09796322e-04, -2.45457670e-06, -1.70320567e-04,\n",
              "           3.46515771e-05, -4.21005936e-04,  6.10405382e-05,\n",
              "           1.32764595e-06,  4.85369267e-06, -2.63438591e-05,\n",
              "           3.37210840e-04, -3.12655884e-05,  2.54708976e-05,\n",
              "          -2.89804933e-04, -4.81626741e-05]]),\n",
              "  array([[-6.01093840e-05,  3.43533459e-03, -1.24506025e-03,\n",
              "           1.80049990e-03, -1.90426865e-03, -4.17261478e-05,\n",
              "          -2.17499408e-03, -1.90010077e-05,  5.52021156e-04,\n",
              "           3.21839099e-04, -4.02366334e-04, -3.06489615e-04,\n",
              "          -5.41288932e-04,  2.29798119e-03,  6.38049409e-04,\n",
              "          -9.68494344e-05, -1.89056259e-03,  2.22236699e-03,\n",
              "           7.32132087e-04,  1.01286195e-03]]),\n",
              "  array([[ 1.12501647e-03, -6.38399668e-03, -1.17347163e-02,\n",
              "          -8.93878158e-03,  6.28226906e-03,  4.30670268e-05,\n",
              "           1.25954699e-03, -8.56240994e-03, -3.68996917e-03,\n",
              "          -2.40320934e-02, -9.95165650e-03,  1.21165839e-02,\n",
              "          -3.42669618e-03, -5.05312754e-03, -2.86287467e-06,\n",
              "          -2.40327746e-02,  3.26327863e-02, -6.97834542e-04,\n",
              "           3.70826001e-02,  5.95062125e-03]]),\n",
              "  array([[ 0.02928355,  0.1966588 , -0.09020384, -0.02140986, -0.0304803 ,\n",
              "          -0.13249072,  0.0868927 , -0.02140279,  0.0205662 , -0.03741374]])))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "np.random.seed(100000)\n",
        "\n",
        "# One hot encoding the labels into 10 classes\n",
        "Y_class = np.array([(i)*[0]+[1]+(9-i)*[0] for i in Y])\n",
        "\n",
        "# Defining the sigmoid activation functions\n",
        "def activation_func(name,z):\n",
        "    def sigmoid(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    def relu(z):\n",
        "        return np.maximum(0, np.asarray(z, dtype=z.dtype))\n",
        "    def tanh(z):\n",
        "        return np.tanh(z)\n",
        "\n",
        "    if name == \"sigmoid\":\n",
        "        return(sigmoid(z))\n",
        "    if name == \"relu\":\n",
        "        return(relu(z))\n",
        "    if name == \"tanh\":\n",
        "        return(tanh(z))\n",
        "\n",
        "# Defininf  the softmax function\n",
        "def softmax(z):\n",
        "    exps = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "# Making random initialized weights and bias for all layers\n",
        "def initialize_weights(num_layers,n_hu):\n",
        "    layer_sizes = [784]+num_layers*[n_hu]+[10]\n",
        "    weight_bias = []\n",
        "    for i in range(len(layer_sizes)-1):\n",
        "        w = np.random.randn(layer_sizes[i], layer_sizes[i+1]) / np.sqrt(layer_sizes[i])\n",
        "        b = np.zeros((1, layer_sizes[i+1]))\n",
        "        weight_bias.append((w,b))\n",
        "    return weight_bias\n",
        "\n",
        "# forward pass\n",
        "def forward(x, weight):\n",
        "    acti = [x]\n",
        "    A = x\n",
        "    for w, b in weight:\n",
        "        z = np.dot(A, w) + b\n",
        "        A = activation_func(\"relu\",z)\n",
        "        acti.append(A)\n",
        "    y_h = softmax(z)\n",
        "    return acti, y_h\n",
        "\n",
        "# backward pass\n",
        "def backward(x, y, acti, y_h,weight_bias, lamda):\n",
        "    m = x.shape[0]\n",
        "    dz = y_h - y\n",
        "    dw = np.dot(acti[-2].T, dz)/m + (lamda * weight_bias[-1][0])/m\n",
        "    db = np.sum(dz, axis=0, keepdims=True)/m\n",
        "    grad = [(dw, db)]\n",
        "    for i in range(len(weight_bias)-1, 0, -1):\n",
        "        dA = np.dot(dz, weight_bias[i][0].T)\n",
        "        dz = dA * acti[i] * (1 - acti[i])\n",
        "        dw = np.dot(acti[i-1].T, dz) / m + (lamda * weight_bias[i-1][0]) / m\n",
        "        db = np.sum(dz, axis=0, keepdims=True) / m\n",
        "        grad.insert(0, (dw, db))\n",
        "    return grad\n",
        "\n",
        "def update(weight_bias, grad, lr):\n",
        "    for i in range(len(weight_bias)):\n",
        "        w, b = weight_bias[i]\n",
        "        dw, db = grad[i]\n",
        "        w = w- lr*dw\n",
        "        b = b - lr* db\n",
        "        weight_bias[i] = (w, b)\n",
        "    return weight_bias\n",
        "\n",
        "def train(x, y,num_layer=3,n_hu=20, num_iter=100, lr=0.1,lamda=0.01):\n",
        "    weight_bias = initialize_weights(num_layer,n_hu)\n",
        "    for epoch in range(num_iter):\n",
        "        acti, y_h = forward(X, weight_bias)\n",
        "        grad = backward(x,y, acti, y_h, weight_bias,lamda)\n",
        "        weights = update(weight_bias, grad, lr)\n",
        "        cost = -np.sum(y * np.log(y_h)) / x.shape[0]\n",
        "        if epoch % 10 == 0:\n",
        "            print(\"Epoch {}: loss = {}\".format(epoch, cost))\n",
        "\n",
        "    weigh = list(zip(*weights))[0]\n",
        "    bia = list(zip(*weights))[1]\n",
        "    return weigh,bia\n",
        "\n",
        "num_layer=3 # Number of layers\n",
        "n_hu=20 # number of hidden units\n",
        "train(X,Y_class,3,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 6\n",
        "\n",
        "Extend your code from problem 5 to implement momentum with your gradient descent. The  momentum value will be passed as a parameter. Your function should perform “epoch” number of  epochs and return the resulting weights."
      ],
      "metadata": {
        "id": "_VuxH7luZL0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANSWER 6"
      ],
      "metadata": {
        "id": "mD7v10sRXIeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(100000)\n",
        "# One hot encoding the labels into 10 classes\n",
        "Y_class = np.array([(i)*[0]+[1]+(9-i)*[0] for i in Y])\n",
        "\n",
        "# Defining the sigmoid activation functions\n",
        "def activation_func(name, z):\n",
        "    def sigmoid(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    def relu(z):\n",
        "        return np.maximum(0, np.asarray(z, dtype=z.dtype))\n",
        "    def tanh(z):\n",
        "        return np.tanh(z)\n",
        "\n",
        "    if name == \"sigmoid\":\n",
        "        return sigmoid(z)\n",
        "    if name == \"relu\":\n",
        "        return relu(z)\n",
        "    if name == \"tanh\":\n",
        "        return tanh(z)\n",
        "\n",
        "# Defininf the softmax function\n",
        "def softmax(z):\n",
        "    exps = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "# Making random initialized weights and bias for all layers\n",
        "def initialize_weights(num_layers, n_hu):\n",
        "    layer_sizes = [784] + num_layers * [n_hu] + [10]\n",
        "    weight_bias = []\n",
        "    for i in range(len(layer_sizes)-1):\n",
        "        w = np.random.randn(layer_sizes[i], layer_sizes[i+1]) / np.sqrt(layer_sizes[i])\n",
        "        b = np.zeros((1, layer_sizes[i+1]))\n",
        "\n",
        "        # Momentum terms\n",
        "        vw = np.zeros_like(w)\n",
        "        vb = np.zeros_like(b)\n",
        "        weight_bias.append((w, b, vw, vb))\n",
        "\n",
        "    return weight_bias\n",
        "\n",
        "# Forward pass\n",
        "def forward(x, weight):\n",
        "    acti = [x]\n",
        "    A = x\n",
        "    for w, b, _, _ in weight:\n",
        "        z = np.dot(A, w) + b\n",
        "        A = activation_func(\"relu\", z)\n",
        "        acti.append(A)\n",
        "    y_h = softmax(z)\n",
        "    return acti, y_h\n",
        "\n",
        "# Backward pass\n",
        "def backward(x, y, acti, y_h, weight_bias, lamda):\n",
        "    m = x.shape[0]\n",
        "    dz = y_h - y\n",
        "    dw = np.dot(acti[-2].T, dz) / m + (lamda * weight_bias[-1][0]) / m\n",
        "    db = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "    grad = [(dw, db)]\n",
        "    for i in range(len(weight_bias)-1, 0, -1):\n",
        "        dA = np.dot(dz, weight_bias[i][0].T)\n",
        "        dz = dA * acti[i] * (1 - acti[i])\n",
        "        dw = np.dot(acti[i-1].T, dz) / m + (lamda * weight_bias[i-1][0]) / m\n",
        "        db = np.sum(dz, axis=0, keepdims=True) / m\n",
        "        grad.insert(0, (dw, db))\n",
        "    return grad\n",
        "\n",
        "# Update weights and biases with momentum\n",
        "def update(weight_bias, grad, lr, mr):\n",
        "    for i in range(len(weight_bias)):\n",
        "        w, b, vw, vb = weight_bias[i]\n",
        "        dw, db = grad[i]\n",
        "        vw = mr * vw - lr * dw\n",
        "        vb = mr * vb - lr * db\n",
        "        w = w + vw\n",
        "        b = b + vb\n",
        "        weight_bias[i] = (w, b, vw, vb)\n",
        "    return weight_bias\n",
        "\n",
        "# Training function\n",
        "def train(x, y, num_layer=3, n_hu=20, num_iter=100, lr=0.1, lamda=0.01, mr=0.9):\n",
        "    weight_bias = initialize_weights(num_layer, n_hu)\n",
        "    for epoch in range(num_iter):\n",
        "        acti, y_h = forward(x, weight_bias)\n",
        "        grad = backward(x, y, acti, y_h, weight_bias, lamda)\n",
        "        weights = update(weight_bias, grad, lr, mr)\n",
        "        cost = -np.sum(y * np.log(y_h)) / x.shape[0]\n",
        "        if epoch % 10 == 0:\n",
        "            print(\"Epoch {}: loss = {}\".format(epoch, cost))\n",
        "\n",
        "    weigh = list(zip(*weights))[0]\n",
        "    bia = list(zip(*weights))[1]\n",
        "    return weigh, bia\n",
        "\n",
        "# Number of layers\n",
        "num_layer = 3\n",
        "# Number of hidden units\n",
        "n_hu = 20\n",
        "# Training\n",
        "train(X, Y_class, num_layer, n_hu)\n"
      ],
      "metadata": {
        "id": "bQmzbafgQtEE",
        "outputId": "6d290a59-ddd6-4f86-b0e6-7e80ae91f8fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 2.31581705892741\n",
            "Epoch 10: loss = 2.2911414773180168\n",
            "Epoch 20: loss = 2.2662832705573037\n",
            "Epoch 30: loss = 2.2369846955694705\n",
            "Epoch 40: loss = 2.1941402330572144\n",
            "Epoch 50: loss = 2.1290399428652034\n",
            "Epoch 60: loss = 2.0376323415987523\n",
            "Epoch 70: loss = 1.9281442935356092\n",
            "Epoch 80: loss = 1.8198586069405762\n",
            "Epoch 90: loss = 1.718615663744177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[ 0.00256269, -0.06600426,  0.05410706, ..., -0.02042667,\n",
              "          -0.0258824 ,  0.07300574],\n",
              "         [-0.06792491, -0.03998797,  0.00957866, ...,  0.01156496,\n",
              "           0.02280197,  0.04485978],\n",
              "         [ 0.04719328, -0.01432972,  0.04285335, ...,  0.00844735,\n",
              "           0.00151292,  0.04007515],\n",
              "         ...,\n",
              "         [ 0.00047192,  0.054467  , -0.07609602, ..., -0.04234831,\n",
              "          -0.03934619, -0.01621961],\n",
              "         [ 0.03255051,  0.05758123,  0.10453074, ..., -0.01574526,\n",
              "          -0.02864778,  0.0713329 ],\n",
              "         [-0.06646997, -0.0318318 ,  0.0167278 , ...,  0.02686988,\n",
              "           0.0103485 ,  0.01300784]]),\n",
              "  array([[ 0.20647325, -0.17974039,  0.39869561,  0.06360451, -0.13121517,\n",
              "          -0.00651895, -0.09443759, -0.41049219, -0.35461708, -0.42359786,\n",
              "           0.09101434, -0.30310132, -0.12815793,  0.20678064,  0.16048677,\n",
              "          -0.01602309, -0.00988201, -0.23308598,  0.10807936,  0.328783  ],\n",
              "         [ 0.22083544,  0.22904533,  0.25441476,  0.23073506,  0.05071301,\n",
              "           0.20013686,  0.03848848,  0.07910575,  0.0619753 ,  0.20898417,\n",
              "          -0.31773394, -0.33631395, -0.02176809,  0.04916035, -0.1313469 ,\n",
              "          -0.07374823,  0.06386663, -0.04232025, -0.07317988, -0.13074593],\n",
              "         [-0.30878177, -0.1200989 , -0.04565325, -0.18702183,  0.06082925,\n",
              "           0.25930843,  0.16713824,  0.42207819,  0.12081868,  0.39412248,\n",
              "           0.01911198, -0.24510661,  0.79728054, -0.0804355 , -0.42712081,\n",
              "          -0.13274981,  0.18288825,  0.05962666,  0.03176603, -0.08361978],\n",
              "         [ 0.23765873,  0.32929026,  0.07951978, -0.0594898 , -0.18335476,\n",
              "          -0.02558764,  0.01815528,  0.10741196, -0.32998419,  0.01936031,\n",
              "           0.1252103 ,  0.2597486 ,  0.48310397,  0.01622303, -0.09089934,\n",
              "           0.08348401,  0.30401877,  0.32780427,  0.29226425, -0.14398904],\n",
              "         [ 0.1896484 , -0.30417497, -0.02371266,  0.17529044, -0.11147983,\n",
              "           0.11762508, -0.1343063 , -0.23991376,  0.29214003,  0.09714046,\n",
              "           0.27607387,  0.43092591,  0.08760101, -0.20802641, -0.28574838,\n",
              "          -0.14782067,  0.16842685, -0.13307025,  0.49393231,  0.05549387],\n",
              "         [ 0.03637579,  0.24709348, -0.08190343,  0.21318094, -0.29165041,\n",
              "          -0.44403457,  0.3216259 ,  0.12518822,  0.23275391,  0.22332814,\n",
              "          -0.16333492, -0.34232985,  0.06005638,  0.21590867, -0.17384625,\n",
              "          -0.15836899, -0.01697687, -0.51712319, -0.04480469,  0.05840346],\n",
              "         [-0.2091321 , -0.20223706,  0.03606162,  0.64185804,  0.29474268,\n",
              "           0.10312142, -0.27867375,  0.10401688,  0.22804466, -0.1763753 ,\n",
              "          -0.12994688,  0.33912874,  0.2276352 , -0.40720394, -0.22058187,\n",
              "           0.1180152 ,  0.39125591, -0.25660099,  0.02709003,  0.23490419],\n",
              "         [ 0.50066466,  0.3088139 , -0.17345698, -0.15673681, -0.14235003,\n",
              "          -0.28868979,  0.18893759,  0.02316815,  0.49025578, -0.18518535,\n",
              "          -0.21374317,  0.46719613,  0.03974619,  0.07592663,  0.30280428,\n",
              "           0.19065093,  0.13938467,  0.17238711, -0.38484753,  0.03842144],\n",
              "         [-0.09868943,  0.00999305, -0.09213516,  0.08148364,  0.54861934,\n",
              "          -0.15776863, -0.36356399, -0.01937529,  0.09664909,  0.17131901,\n",
              "           0.37902674, -0.3421886 , -0.00127657,  0.09495968, -0.23189081,\n",
              "           0.20744843,  0.35317009,  0.16224492,  0.20292229,  0.14783152],\n",
              "         [ 0.40090323, -0.22495139,  0.16571208, -0.11286801,  0.19688747,\n",
              "           0.07846068,  0.19965695,  0.10086159,  0.12577107, -0.02253867,\n",
              "          -0.10383043,  0.13442616, -0.1065581 , -0.09724195, -0.02689058,\n",
              "           0.19853196,  0.03575542,  0.01306189,  0.47935008, -0.30237711],\n",
              "         [ 0.09523805,  0.06033386,  0.23335502, -0.04029242,  0.23698218,\n",
              "          -0.35923369, -0.27203548, -0.04982323,  0.05634885,  0.27860237,\n",
              "          -0.00428926, -0.46655293,  0.11256089, -0.26809308, -0.21057408,\n",
              "          -0.01630879,  0.11180311,  0.14698194,  0.35814011, -0.08191937],\n",
              "         [-0.57599303, -0.16907974, -0.26968637,  0.13722812,  0.23150738,\n",
              "           0.12651663, -0.01471515, -0.08118966,  0.10262987,  0.12142086,\n",
              "          -0.29192754, -0.01271819, -0.01743203, -0.24270823,  0.15711226,\n",
              "          -0.3451893 , -0.13840483,  0.20442342,  0.11767654, -0.18609385],\n",
              "         [ 0.104091  , -0.07903554, -0.03672574,  0.30236024, -0.12426028,\n",
              "          -0.24483097, -0.02159253,  0.13016933, -0.1427727 ,  0.17513392,\n",
              "           0.10756919, -0.0596291 , -0.06441704,  0.04948069, -0.17339628,\n",
              "           0.00426584, -0.11645002, -0.02964574, -0.37288201,  0.25911214],\n",
              "         [-0.11633163, -0.25004242, -0.14264694,  0.04979063, -0.13524876,\n",
              "          -0.44931239,  0.01795727,  0.18964582, -0.24129566,  0.24315384,\n",
              "          -0.36836025,  0.17149573, -0.13749044, -0.30003235, -0.2704692 ,\n",
              "          -0.50899691, -0.04165245,  0.23845365,  0.09550545, -0.10985642],\n",
              "         [ 0.09049524,  0.1588789 ,  0.04152408,  0.35772494, -0.07680837,\n",
              "           0.05181683,  0.456327  , -0.00658675,  0.26942101,  0.37439235,\n",
              "          -0.05098607, -0.14653733, -0.19763307,  0.01274562,  0.31831409,\n",
              "          -0.14995427, -0.33671204,  0.13043998,  0.1456928 , -0.19464315],\n",
              "         [ 0.73608989,  0.016561  ,  0.21249682,  0.39341711, -0.03674435,\n",
              "          -0.26024059,  0.12132243,  0.22356769,  0.27999803, -0.12588613,\n",
              "           0.11570499,  0.14507966,  0.12306364,  0.7841476 , -0.11314141,\n",
              "           0.01929952,  0.03069997,  0.10978907, -0.17352295,  0.29355028],\n",
              "         [ 0.12148977,  0.00741054, -0.3743022 ,  0.05061229,  0.29104811,\n",
              "          -0.20256867, -0.36222707,  0.04007685,  0.29304104, -0.05798069,\n",
              "          -0.12099036,  0.01977233,  0.04773299,  0.08334589,  0.33569161,\n",
              "          -0.33554333, -0.09123203, -0.33952041,  0.0622801 , -0.1861037 ],\n",
              "         [-0.0562379 , -0.07131302,  0.00292615, -0.06220701,  0.00287012,\n",
              "           0.10979521, -0.2062946 ,  0.13190646, -0.00869212,  0.24503591,\n",
              "          -0.05677989,  0.29145291, -0.01146936, -0.15727962, -0.21930669,\n",
              "          -0.37780824,  0.14607684,  0.26094105,  0.18278063,  0.04265683],\n",
              "         [-0.14620435,  0.15293818,  0.0584231 , -0.11789715,  0.32549194,\n",
              "          -0.16702229,  0.33610445,  0.20939349,  0.16015061,  0.19472152,\n",
              "          -0.33411617, -0.21193891, -0.13649965, -0.19187611,  0.23029393,\n",
              "          -0.19230042,  0.07697183,  0.18069414,  0.17827175, -0.47560125],\n",
              "         [ 0.54026447,  0.06156802, -0.18532641, -0.21801395,  0.04615208,\n",
              "           0.21687461,  0.23880422, -0.10957164,  0.36261938,  0.18272602,\n",
              "          -0.01701288,  0.09764008,  0.13485354,  0.06749223,  0.12158591,\n",
              "          -0.52526422,  0.06956894, -0.04900577,  0.11258785, -0.00290287]]),\n",
              "  array([[-1.01320579e-01,  2.59473275e-01,  1.39888679e-01,\n",
              "           9.88895052e-02,  8.53758633e-02, -2.99760297e-01,\n",
              "          -3.78948649e-01,  3.67124038e-01,  1.61670101e-01,\n",
              "          -8.04892041e-02, -1.20103750e-02, -1.90721148e-01,\n",
              "           1.74585965e-01,  7.60955690e-02,  1.90731453e-02,\n",
              "           6.36825522e-01,  3.73805635e-01, -3.06104786e-01,\n",
              "           4.21950905e-01,  4.73054488e-01],\n",
              "         [-3.48492631e-01,  6.33176708e-02,  1.09088051e-01,\n",
              "          -5.63326219e-01,  4.46055201e-01,  1.89749329e-01,\n",
              "          -2.71660174e-01, -4.79968361e-01, -1.91069006e-01,\n",
              "           1.61840358e-01, -3.28335695e-01, -2.31894382e-01,\n",
              "          -2.98267508e-01, -1.82306526e-01,  2.74490540e-01,\n",
              "          -4.46436593e-01,  1.80781732e-01, -1.00729680e-02,\n",
              "           1.64893185e-01,  1.05698647e-02],\n",
              "         [ 1.07164820e-01,  1.35026352e-01, -1.01659986e-01,\n",
              "           2.09266677e-02, -2.42628219e-03,  1.58429932e-01,\n",
              "          -2.15425295e-01, -1.23128537e-01,  2.10516965e-01,\n",
              "          -2.47526089e-01,  2.12722965e-01,  3.65874051e-01,\n",
              "           4.23484210e-02,  1.67214220e-01, -2.11391227e-01,\n",
              "          -3.10669071e-01, -8.16591878e-02,  1.54230585e-01,\n",
              "          -1.88231686e-01, -2.43254587e-01],\n",
              "         [ 2.36407867e-02, -1.47936469e-01, -1.75537999e-01,\n",
              "          -5.20502109e-02,  5.56224615e-02, -3.08558846e-01,\n",
              "          -9.56994184e-02,  5.25187699e-02, -4.09730668e-01,\n",
              "          -3.58803678e-01,  3.24351999e-01,  4.73533633e-02,\n",
              "           2.12656382e-01,  4.61096717e-01,  1.65015713e-01,\n",
              "          -6.01061973e-03, -3.19394691e-01, -1.02016785e-01,\n",
              "           2.44551441e-01, -2.43719627e-01],\n",
              "         [ 2.96529595e-01,  6.50594105e-02,  3.35562676e-01,\n",
              "           8.04433839e-03,  1.86082268e-01, -1.19291817e-01,\n",
              "           6.19239522e-02,  5.59621495e-01, -2.10424924e-01,\n",
              "           5.67619574e-01, -2.47024299e-01,  1.66875868e-01,\n",
              "          -1.82231543e-01,  1.95856240e-01, -8.05612322e-02,\n",
              "          -3.89310253e-02, -1.82481614e-01,  8.32089716e-02,\n",
              "          -2.31834664e-01, -1.16563280e-02],\n",
              "         [ 3.92132492e-02,  2.07914982e-01, -5.19025417e-02,\n",
              "          -4.10639252e-01,  6.48954573e-01,  6.80591612e-02,\n",
              "           3.62281492e-02, -4.09627979e-02, -2.91218987e-01,\n",
              "           1.97725100e-01, -1.05364848e-02,  8.34176368e-02,\n",
              "          -1.77217295e-01, -3.45728911e-01,  1.83579479e-01,\n",
              "          -1.38639451e-01,  2.80563253e-01,  8.71400403e-02,\n",
              "          -1.73850543e-01, -2.37847218e-01],\n",
              "         [ 7.85870452e-02,  2.36040677e-01, -4.92592240e-01,\n",
              "           1.80807730e-01,  5.81803406e-01,  9.08754053e-02,\n",
              "           3.37974335e-01,  2.43466721e-01, -1.96765246e-01,\n",
              "           7.79427214e-02, -1.54752415e-01, -1.49768053e-01,\n",
              "           1.16140468e-01, -2.98963081e-01, -4.50334220e-01,\n",
              "           2.52112315e-01, -2.79945595e-01, -3.82514438e-01,\n",
              "           3.65722867e-02, -1.46982207e-01],\n",
              "         [-8.90304501e-02,  2.00290632e-01, -3.27221961e-01,\n",
              "          -1.42865744e-01, -3.38948638e-02, -1.16412471e-01,\n",
              "          -2.95830655e-01, -1.21068277e-01, -2.32256440e-02,\n",
              "          -2.97871742e-01,  2.05688808e-01, -3.09055995e-01,\n",
              "          -8.83155539e-02, -7.15592275e-02, -2.53429690e-01,\n",
              "           5.50404692e-01,  3.57683418e-01, -1.53550504e-01,\n",
              "          -5.66823894e-02,  1.37360873e-01],\n",
              "         [-8.09690145e-02, -1.62342591e-01, -6.49335942e-02,\n",
              "          -8.47191415e-02,  1.11858360e-01, -1.61317430e-01,\n",
              "          -2.54616262e-01,  1.49618624e-01,  2.28999462e-01,\n",
              "           2.67433652e-01,  2.36177457e-01,  3.39495626e-01,\n",
              "           3.68706309e-01, -1.32074536e-01, -4.27031716e-01,\n",
              "           1.85943399e-01,  1.88769014e-01,  1.25752016e-01,\n",
              "           3.78812815e-01, -3.28656101e-02],\n",
              "         [ 9.16739570e-02, -2.71573622e-03,  4.18975667e-02,\n",
              "           1.61700293e-01,  1.23893960e-01,  1.73524675e-01,\n",
              "           3.79280765e-01, -1.01611409e-01, -1.48320016e-02,\n",
              "           3.35718979e-01, -2.17488571e-02,  2.80611251e-01,\n",
              "           4.41162667e-02, -1.34184958e-01, -2.37310828e-01,\n",
              "           1.64063043e-01, -1.15105964e-01,  1.27174169e-01,\n",
              "           9.05655708e-02,  2.34112201e-01],\n",
              "         [ 1.16311412e-01, -1.57484747e-01,  8.97322922e-02,\n",
              "           9.70232692e-02,  1.63118360e-02, -3.64014631e-01,\n",
              "          -8.08172808e-02,  2.01902261e-02, -5.15527060e-02,\n",
              "           4.00315198e-01,  3.95653160e-01,  1.57132296e-01,\n",
              "           2.18003065e-01,  4.21063893e-02, -4.13647393e-02,\n",
              "           6.53339655e-03,  6.20465615e-02, -4.58142153e-01,\n",
              "          -3.56122981e-01, -2.55752067e-01],\n",
              "         [ 2.07743253e-01, -6.67799702e-02, -2.77080799e-01,\n",
              "           2.84508572e-01, -1.32954954e-01, -1.28542293e-01,\n",
              "           3.00920654e-03,  1.24543109e-01, -2.05762946e-01,\n",
              "          -1.88585195e-01,  3.75507152e-02, -1.20883727e-01,\n",
              "          -1.97180412e-01,  3.56131637e-01, -3.20739132e-02,\n",
              "           2.17207727e-01,  1.55267474e-01, -1.44344759e-02,\n",
              "           2.79747401e-01,  8.95264729e-02],\n",
              "         [-7.85696677e-02,  1.98390713e-01,  4.10471505e-01,\n",
              "           3.17517364e-01,  3.25018649e-01, -3.77932315e-01,\n",
              "           1.54212622e-01, -3.21813212e-01, -4.90331015e-01,\n",
              "           1.34792599e-02,  2.69612050e-01,  1.11413065e-01,\n",
              "           5.50237909e-01,  1.40202526e-01,  4.56957395e-02,\n",
              "          -1.65051212e-02, -1.98744091e-01,  1.89250341e-01,\n",
              "          -1.71808786e-01,  1.09806929e-01],\n",
              "         [-2.01729334e-01,  7.77116341e-02,  1.21147065e-01,\n",
              "          -4.58965202e-02, -3.80485807e-01,  2.44796634e-01,\n",
              "           1.53506392e-01,  3.82289153e-02, -1.69265877e-02,\n",
              "           1.44759182e-01,  4.54210751e-01, -5.46472855e-01,\n",
              "          -3.44730437e-02, -1.01195604e-01, -1.72248733e-01,\n",
              "          -1.36310889e-01,  4.98406703e-01, -3.06170931e-01,\n",
              "           3.02650946e-01, -2.29478260e-01],\n",
              "         [ 2.71273912e-01, -6.29831296e-03,  5.44488270e-02,\n",
              "           1.36854596e-01, -2.11898654e-01, -1.97047013e-01,\n",
              "          -1.38895917e-01, -1.84576167e-01, -1.19625707e-01,\n",
              "           9.38229473e-02, -2.48011507e-01,  4.82681323e-02,\n",
              "          -1.66868013e-01, -4.78461345e-02,  3.11702864e-01,\n",
              "          -3.67570564e-01,  1.21046693e-02,  6.25886112e-02,\n",
              "           5.02978943e-02, -7.96636948e-02],\n",
              "         [ 4.18808936e-02, -6.49443195e-02, -3.27408211e-01,\n",
              "          -3.51569318e-01,  1.33544451e-01,  2.71784917e-01,\n",
              "          -6.24586391e-02,  1.04714737e-01, -3.51244684e-01,\n",
              "          -1.14303747e-01, -8.27836174e-02, -2.31977609e-01,\n",
              "           3.03198417e-01,  1.03875889e-01,  4.34754141e-04,\n",
              "          -3.64219356e-01,  8.49726658e-02, -6.87177770e-02,\n",
              "          -1.51657637e-01, -4.93796211e-02],\n",
              "         [-8.77461656e-02, -2.18044056e-01,  3.62788479e-01,\n",
              "           2.16757974e-01,  4.34548275e-02, -3.52193136e-02,\n",
              "          -7.79673441e-02,  4.09647903e-01, -1.08441001e-01,\n",
              "          -8.64012095e-02,  4.74789565e-03,  2.33517414e-01,\n",
              "          -1.65213324e-01,  7.63879012e-02, -4.24602013e-02,\n",
              "           2.67266456e-01, -3.75439953e-01, -2.91590412e-02,\n",
              "          -3.12473899e-02, -4.70359833e-02],\n",
              "         [ 3.86849249e-02,  1.79616690e-01,  9.60166849e-03,\n",
              "           4.31069157e-01,  3.17069264e-02, -2.57739665e-01,\n",
              "           5.07524052e-02,  3.32565912e-01,  1.34755721e-01,\n",
              "          -6.71539919e-02, -5.96484881e-02, -3.37520337e-02,\n",
              "          -2.56668786e-01, -3.35969173e-01,  1.83527544e-01,\n",
              "           3.28143604e-02, -1.99660241e-02,  1.64451442e-02,\n",
              "           2.77644016e-01,  4.97400967e-01],\n",
              "         [-3.07237432e-02, -7.59875711e-02,  1.65129485e-01,\n",
              "           3.08324459e-01,  3.69825722e-01,  1.82393368e-01,\n",
              "           2.82095182e-01, -2.62100024e-02,  1.43201013e-01,\n",
              "           6.66998080e-02,  1.49288253e-01,  3.00333722e-01,\n",
              "          -2.71608917e-01,  1.14913987e-01, -3.17428602e-01,\n",
              "          -2.91405576e-01,  3.84589401e-02, -2.17213372e-02,\n",
              "          -2.73426863e-01,  5.67528559e-01],\n",
              "         [ 2.05295444e-01, -2.57229214e-02, -2.54039775e-01,\n",
              "           2.48355276e-01, -3.00976267e-02,  1.74762500e-01,\n",
              "           1.79403938e-01,  3.26463749e-01,  2.08039998e-01,\n",
              "           3.84561511e-01,  1.93854692e-01,  1.63255714e-01,\n",
              "           3.87037240e-01, -7.75067860e-02, -2.28645722e-01,\n",
              "          -2.14303859e-02,  2.40326472e-01,  1.06541098e-01,\n",
              "          -3.07805836e-01,  1.36273911e-01]]),\n",
              "  array([[ 0.17035202,  0.14131957, -0.41816856, -0.35086821, -0.29228806,\n",
              "           0.03299004, -0.04202643, -0.48735671,  0.00771412, -0.49325381],\n",
              "         [ 0.03237416, -0.37936414,  0.04783126, -0.33422982,  0.40511586,\n",
              "           0.05714149, -0.42738536,  0.1525098 , -0.10521663,  0.41069895],\n",
              "         [ 0.43766884,  0.09007677, -0.31846347,  0.30054296, -0.24284382,\n",
              "           0.34017997, -0.58071541, -0.23617785,  0.91483061,  0.06594048],\n",
              "         [ 0.04707293, -0.40820127, -0.2193582 ,  0.46409695, -0.34575057,\n",
              "           0.43694972, -0.47529698,  0.16834259,  0.02091405,  0.65028955],\n",
              "         [ 0.38944901, -0.14643428, -0.37845961,  0.35001062,  0.47757668,\n",
              "           0.38241905, -0.6456735 , -0.51797724, -0.01458314, -0.20016724],\n",
              "         [ 0.26294194,  0.02111141,  0.54743532,  0.16512636, -0.43254254,\n",
              "           0.1946831 ,  0.13343381, -0.26202117,  0.05432913,  0.08495813],\n",
              "         [ 0.37837397,  0.30992508, -0.14161794, -0.25208137, -0.19794598,\n",
              "          -0.00390273,  0.11577457, -0.07924581, -0.18353817,  0.12254948],\n",
              "         [ 0.03398552, -0.82781077,  0.1734454 ,  0.10771405, -0.44782249,\n",
              "          -0.598203  , -0.33191549, -0.0381885 ,  0.04459418,  0.16409449],\n",
              "         [ 0.11056674,  0.14036164, -0.29577187,  0.05391915,  0.30501348,\n",
              "          -0.07548018, -0.06842567,  0.12184857,  0.35818905,  0.13995089],\n",
              "         [ 1.24020854, -0.19518435, -0.17867435,  0.08879624, -0.49029447,\n",
              "           0.02242203,  0.10401195, -0.39133881,  0.3460018 , -0.10551589],\n",
              "         [-0.41244852, -0.44604097,  0.13834145,  0.12016783, -0.11257315,\n",
              "          -0.16553143,  0.1677209 ,  0.40046106,  0.2221224 , -0.17408419],\n",
              "         [ 1.3188939 ,  0.41605626, -0.13534614,  0.80479635, -0.54118328,\n",
              "           0.60196265, -0.48646677, -0.37331119,  0.32112902, -0.57046189],\n",
              "         [-0.38482861, -0.22282217,  0.8758213 ,  0.13933877,  0.07245699,\n",
              "          -0.24844478, -0.35745211,  0.53668403, -0.47046981, -0.41988691],\n",
              "         [-0.26493484, -0.14913232,  0.41806447,  0.69298439,  0.00628379,\n",
              "           0.44588043, -0.28403756, -0.23154238,  0.01787725,  0.27578909],\n",
              "         [ 0.0171815 , -0.3764649 , -0.09102802, -0.43078926,  0.37162629,\n",
              "          -0.23936329,  0.10738955, -0.16013406, -0.1031713 ,  0.21906927],\n",
              "         [-0.19556599, -0.70836984,  0.0523745 , -0.08601417,  0.86807178,\n",
              "          -0.29403778, -0.17593775,  0.5621336 , -0.14576163,  0.79005309],\n",
              "         [-1.32943804,  0.41005476,  0.36865067, -1.03351918,  0.0368929 ,\n",
              "          -0.67426744,  1.02059807,  0.69908323, -0.0264668 ,  0.028771  ],\n",
              "         [-0.05442282, -0.15118087, -0.20424229,  0.11570917, -0.07402425,\n",
              "           0.00342596,  0.16775817, -0.05353647,  0.3718064 , -0.11148625],\n",
              "         [-1.47690046, -0.70240893,  0.09467113, -1.0428165 ,  1.00830049,\n",
              "          -0.82833922,  0.58408858,  0.35166137,  0.0193745 ,  0.67695043],\n",
              "         [-0.21232682, -0.55112248, -0.69533405,  0.11323454,  0.24722111,\n",
              "           0.16065643, -0.62094664, -0.10704914,  0.22646402,  0.64780508]])),\n",
              " (array([[-4.55459024e-03,  1.84686330e-03,  2.52822063e-03,\n",
              "           1.03487011e-02,  4.06149226e-03, -1.69169399e-03,\n",
              "           6.82933046e-03, -1.84480878e-04,  4.69866219e-04,\n",
              "           6.83354262e-04, -2.67970518e-03, -9.40875923e-04,\n",
              "           2.79324020e-04,  3.16534553e-03, -2.94643736e-04,\n",
              "           1.04467885e-02, -2.46780963e-05,  8.65377897e-04,\n",
              "           2.07378670e-03,  2.19700402e-03]]),\n",
              "  array([[-0.03088421,  0.02557596, -0.01579393,  0.0271827 ,  0.03406118,\n",
              "          -0.0013108 ,  0.01496449,  0.02337323,  0.03124698,  0.02492555,\n",
              "           0.04132804,  0.02564746,  0.03397568,  0.06301725,  0.00247965,\n",
              "          -0.00135563, -0.00322626,  0.04253257,  0.06368905,  0.04319503]]),\n",
              "  array([[ 1.76588542e-02,  6.19649187e-02, -1.60370465e-02,\n",
              "          -9.92163052e-03,  5.82621909e-02,  1.38949748e-04,\n",
              "           4.34238651e-02, -3.05442861e-02, -1.56221167e-02,\n",
              "          -1.72235583e-02, -5.81567360e-03,  1.81987688e-01,\n",
              "           1.21641287e-01,  7.71049841e-02, -1.04861537e-05,\n",
              "          -1.26318058e-01,  4.19513104e-01, -8.34830215e-03,\n",
              "           5.09204022e-02, -7.30772437e-02]]),\n",
              "  array([[-0.09078147,  1.510702  ,  0.03871703, -0.15991874, -0.40563336,\n",
              "           0.25843521,  0.60822371, -0.60908663, -0.31592325, -0.8347345 ]])))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0BmOsiwxWzgb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}